{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOVGgIFTi4AyGwyiBpcOKTR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c274ed5d638b41ecba477cb38fb75644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acb7a719651241a783836094ce3ac74c",
              "IPY_MODEL_11511ceb99fb43d88b301e136f45794b",
              "IPY_MODEL_72c09a1f6de74135a85a0d2bb5713c5f"
            ],
            "layout": "IPY_MODEL_068e6f6ddbc944c89c82cdd8710a9ff5"
          }
        },
        "acb7a719651241a783836094ce3ac74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfa9ca437f7044bfb91fd8b6a8e198ee",
            "placeholder": "​",
            "style": "IPY_MODEL_6c8be6372f8e4c98bd36835d80c02363",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "11511ceb99fb43d88b301e136f45794b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db202ca452b84280954c98e0a5fb58d1",
            "max": 412,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8b77a7198ff9422db0c256296200a1bd",
            "value": 412
          }
        },
        "72c09a1f6de74135a85a0d2bb5713c5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deb42771c1644bf6816f240fa51dd336",
            "placeholder": "​",
            "style": "IPY_MODEL_ac9d59af248d4a6ab697c0403299b1f6",
            "value": " 412/412 [00:00&lt;00:00, 40.6kB/s]"
          }
        },
        "068e6f6ddbc944c89c82cdd8710a9ff5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa9ca437f7044bfb91fd8b6a8e198ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c8be6372f8e4c98bd36835d80c02363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db202ca452b84280954c98e0a5fb58d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b77a7198ff9422db0c256296200a1bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "deb42771c1644bf6816f240fa51dd336": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9d59af248d4a6ab697c0403299b1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d2be1d3c77f4f488230546661b0a11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b110c58931374501a4f7f25eae59a229",
              "IPY_MODEL_f0cafb79856f40f1bd703124c1183166",
              "IPY_MODEL_a9f9e37b0a9b494c82a0ba9d87fdf14b"
            ],
            "layout": "IPY_MODEL_a2a8d4c9f9a848bca384a2e2bda3871d"
          }
        },
        "b110c58931374501a4f7f25eae59a229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a18a55c7a3b64fc98d1e29605772cd53",
            "placeholder": "​",
            "style": "IPY_MODEL_0e3fbee35d08455faa911a3bc8387d1c",
            "value": "spm.model: 100%"
          }
        },
        "f0cafb79856f40f1bd703124c1183166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00b4dc6fa71c4978aa264dc5e790b893",
            "max": 2464616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc13d13bd0ae4b39be5b0b738374bbe9",
            "value": 2464616
          }
        },
        "a9f9e37b0a9b494c82a0ba9d87fdf14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8024b01f73994747925809c3606c0936",
            "placeholder": "​",
            "style": "IPY_MODEL_5ac2b04d6eda4709962a552cc42dae0d",
            "value": " 2.46M/2.46M [00:01&lt;00:00, 1.89MB/s]"
          }
        },
        "a2a8d4c9f9a848bca384a2e2bda3871d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a18a55c7a3b64fc98d1e29605772cd53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e3fbee35d08455faa911a3bc8387d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00b4dc6fa71c4978aa264dc5e790b893": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc13d13bd0ae4b39be5b0b738374bbe9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8024b01f73994747925809c3606c0936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac2b04d6eda4709962a552cc42dae0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c21c379d22324010bb50e678bcf7ab4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51bd7d9f9edc410197893f5a608e67b0",
              "IPY_MODEL_9bbc521dcb1b4598b8d1cb193604fa28",
              "IPY_MODEL_6ece4b419aa6426ab8adc065d4c6e71f"
            ],
            "layout": "IPY_MODEL_cc6cebea7fed4c13b560847446563a2e"
          }
        },
        "51bd7d9f9edc410197893f5a608e67b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0250ceddd08e4dbcb22f33bd721aed39",
            "placeholder": "​",
            "style": "IPY_MODEL_5fd798fe1d8844648b16250e0ad1c951",
            "value": "tokenizer.json: "
          }
        },
        "9bbc521dcb1b4598b8d1cb193604fa28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45f49caca132485aaf9b9ae87dced40e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6538caf41cb3490f9c3f133979302d4c",
            "value": 1
          }
        },
        "6ece4b419aa6426ab8adc065d4c6e71f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c2e58bd23824e91b2c1221bdaf7e46f",
            "placeholder": "​",
            "style": "IPY_MODEL_0f0085df8341490bb8055de71a26e2d5",
            "value": " 8.66M/? [00:00&lt;00:00, 21.5MB/s]"
          }
        },
        "cc6cebea7fed4c13b560847446563a2e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0250ceddd08e4dbcb22f33bd721aed39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fd798fe1d8844648b16250e0ad1c951": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45f49caca132485aaf9b9ae87dced40e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "6538caf41cb3490f9c3f133979302d4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c2e58bd23824e91b2c1221bdaf7e46f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f0085df8341490bb8055de71a26e2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d70d9cc5b04a43b282ac0650083587a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b96ce79c941b4539bd8f21894da805b1",
              "IPY_MODEL_631f2c38f9da432195ec337e9a6384d4",
              "IPY_MODEL_7823a81a1866442585525d72d2571ec8"
            ],
            "layout": "IPY_MODEL_8107945444f941f08f3373f289b6f0cc"
          }
        },
        "b96ce79c941b4539bd8f21894da805b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e07dc49fd1ae4b7cbeeeb5880c062ce2",
            "placeholder": "​",
            "style": "IPY_MODEL_2341fa106d824720b9a3bacbdac46e69",
            "value": "added_tokens.json: 100%"
          }
        },
        "631f2c38f9da432195ec337e9a6384d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6ce0d6ea7c549029778e4d3a1ec2adb",
            "max": 23,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c1cd8886bd14a81aa635d2f5310feb7",
            "value": 23
          }
        },
        "7823a81a1866442585525d72d2571ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2526145edff145479bc02999ee6a0410",
            "placeholder": "​",
            "style": "IPY_MODEL_aa69bfbf1b764fb0b6ae5dba7b1360a2",
            "value": " 23.0/23.0 [00:00&lt;00:00, 2.52kB/s]"
          }
        },
        "8107945444f941f08f3373f289b6f0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e07dc49fd1ae4b7cbeeeb5880c062ce2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2341fa106d824720b9a3bacbdac46e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6ce0d6ea7c549029778e4d3a1ec2adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1cd8886bd14a81aa635d2f5310feb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2526145edff145479bc02999ee6a0410": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa69bfbf1b764fb0b6ae5dba7b1360a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1c72076a75f45628906b066418d8ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9eaae92022d54f9a87ddbf03e1e88933",
              "IPY_MODEL_6a8484b52bd0452da3f447caa875f83f",
              "IPY_MODEL_bbcb8fb19764405da21f5038aaccc361"
            ],
            "layout": "IPY_MODEL_a0ceadb4e2014f68991626e867e12a6a"
          }
        },
        "9eaae92022d54f9a87ddbf03e1e88933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc955cc79af1466fa3c1abb3d4fca086",
            "placeholder": "​",
            "style": "IPY_MODEL_592ef782956d4583b88f9629a41fb205",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "6a8484b52bd0452da3f447caa875f83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90ab06abe29649f3b3392cd407af450b",
            "max": 173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0eb5e0d77b3249aeb0dd93f7b1f9e391",
            "value": 173
          }
        },
        "bbcb8fb19764405da21f5038aaccc361": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7317deb67d4441bd82560ff77d7ae5a4",
            "placeholder": "​",
            "style": "IPY_MODEL_32b93181b78d491297ba924270e9b9ca",
            "value": " 173/173 [00:00&lt;00:00, 19.7kB/s]"
          }
        },
        "a0ceadb4e2014f68991626e867e12a6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc955cc79af1466fa3c1abb3d4fca086": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "592ef782956d4583b88f9629a41fb205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "90ab06abe29649f3b3392cd407af450b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0eb5e0d77b3249aeb0dd93f7b1f9e391": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7317deb67d4441bd82560ff77d7ae5a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b93181b78d491297ba924270e9b9ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "135d8beccf21438aa4a698f3e4ece8de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_937abcbd86c5441ba9a2be037cd88995",
              "IPY_MODEL_0f392cc0a0dc45ecadea98aa0650d6e8",
              "IPY_MODEL_4c8340f5b5704a4aa36539a1a94917ce"
            ],
            "layout": "IPY_MODEL_6ddf1fbaf1f947cbaeab0a76745efe82"
          }
        },
        "937abcbd86c5441ba9a2be037cd88995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a20ff983b914ed69cc9e4b8e044e69e",
            "placeholder": "​",
            "style": "IPY_MODEL_3bcea574e6d24a5da4bd708f6b947ddb",
            "value": "config.json: "
          }
        },
        "0f392cc0a0dc45ecadea98aa0650d6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_098e7b0972934e7fbf46bbc961a5eef7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99df6b38ec6a4eb08200215073364087",
            "value": 1
          }
        },
        "4c8340f5b5704a4aa36539a1a94917ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f2cdd3696f24bebaef6e82d68e43193",
            "placeholder": "​",
            "style": "IPY_MODEL_6b1f986323d94728a9599ef8f3c695a6",
            "value": " 1.04k/? [00:00&lt;00:00, 101kB/s]"
          }
        },
        "6ddf1fbaf1f947cbaeab0a76745efe82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a20ff983b914ed69cc9e4b8e044e69e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bcea574e6d24a5da4bd708f6b947ddb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "098e7b0972934e7fbf46bbc961a5eef7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "99df6b38ec6a4eb08200215073364087": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f2cdd3696f24bebaef6e82d68e43193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b1f986323d94728a9599ef8f3c695a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f9fb2301cb463381569ebcb29a7795": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff8fad3b15f6459cb7c8eacd5b16f9e4",
              "IPY_MODEL_d9f7502a121e4d889e5c59a4afc1a2db",
              "IPY_MODEL_0ac0d68e7ec448b78c757be30a716d2f"
            ],
            "layout": "IPY_MODEL_c64fc7c2a73c43dc9c0132712dd0446d"
          }
        },
        "ff8fad3b15f6459cb7c8eacd5b16f9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_734f57b7cbb5446cae09d636ee8f9822",
            "placeholder": "​",
            "style": "IPY_MODEL_ef2af4bd0338494498e9d2866a2d4ae9",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "d9f7502a121e4d889e5c59a4afc1a2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d37f76621684973a7e3a022476e55bb",
            "max": 737766955,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77e2a0aa98674f6199d0af92d119b2ce",
            "value": 737766955
          }
        },
        "0ac0d68e7ec448b78c757be30a716d2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a13df89b9622460c9a6906fea7b189bf",
            "placeholder": "​",
            "style": "IPY_MODEL_961c987f7a6843418746bb26158c3a28",
            "value": " 738M/738M [00:44&lt;00:00, 17.7MB/s]"
          }
        },
        "c64fc7c2a73c43dc9c0132712dd0446d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "734f57b7cbb5446cae09d636ee8f9822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef2af4bd0338494498e9d2866a2d4ae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d37f76621684973a7e3a022476e55bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77e2a0aa98674f6199d0af92d119b2ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a13df89b9622460c9a6906fea7b189bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961c987f7a6843418746bb26158c3a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f5a29bc57c74aef857767fc30e6b3c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5333a897833849a7823dc887425ec891",
              "IPY_MODEL_cef1bf4690fc4db4bb8710c383d3af68",
              "IPY_MODEL_ea87fe31581346a996c6f98dda92366f"
            ],
            "layout": "IPY_MODEL_eca60e51d664407d9def45623f682c77"
          }
        },
        "5333a897833849a7823dc887425ec891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edc4e95f83ba47b4bcba22801038bd4e",
            "placeholder": "​",
            "style": "IPY_MODEL_1d530217c19040e6a635692840bd8931",
            "value": "model.safetensors: 100%"
          }
        },
        "cef1bf4690fc4db4bb8710c383d3af68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bf29cd16ef449668b94c914d9240870",
            "max": 737723472,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_346172f2bde44d30a7a5b173c31f26d6",
            "value": 737723472
          }
        },
        "ea87fe31581346a996c6f98dda92366f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ede3a11c6714ffda8d30a555ff37d57",
            "placeholder": "​",
            "style": "IPY_MODEL_ec82ad6dacb0425086b729c7738862b3",
            "value": " 738M/738M [01:02&lt;00:00, 11.7MB/s]"
          }
        },
        "eca60e51d664407d9def45623f682c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edc4e95f83ba47b4bcba22801038bd4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d530217c19040e6a635692840bd8931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bf29cd16ef449668b94c914d9240870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "346172f2bde44d30a7a5b173c31f26d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ede3a11c6714ffda8d30a555ff37d57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec82ad6dacb0425086b729c7738862b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76e784e227e74025819a5785ba1c0e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a84886a4a12434da318020515c5f933",
              "IPY_MODEL_bc6bb180e58443da8ab3b4e6b79616df",
              "IPY_MODEL_e3fc58af685a41768f24bfc2fbb69603"
            ],
            "layout": "IPY_MODEL_bad1e02e27ed4aeeb620756260b21725"
          }
        },
        "0a84886a4a12434da318020515c5f933": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc3269e0e47b43cba323a3fe99118cea",
            "placeholder": "​",
            "style": "IPY_MODEL_725b8cf05c4742078cb536a50df00d9b",
            "value": "tokenizer_config.json: "
          }
        },
        "bc6bb180e58443da8ab3b4e6b79616df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d881cef4b44e4d408a6976163edbee6e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4da4f1137cfe434bb685534c9f51b009",
            "value": 1
          }
        },
        "e3fc58af685a41768f24bfc2fbb69603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b95b0ec154814a559aa1d2faf41b9ce0",
            "placeholder": "​",
            "style": "IPY_MODEL_f21adab98d1b49778ac17e14cf2ae3ec",
            "value": " 1.61k/? [00:00&lt;00:00, 101kB/s]"
          }
        },
        "bad1e02e27ed4aeeb620756260b21725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc3269e0e47b43cba323a3fe99118cea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "725b8cf05c4742078cb536a50df00d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d881cef4b44e4d408a6976163edbee6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4da4f1137cfe434bb685534c9f51b009": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b95b0ec154814a559aa1d2faf41b9ce0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21adab98d1b49778ac17e14cf2ae3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f0f0c11906484e5d8c6d295d7d4fa778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_30673510b9b942b182b2901176daa2c5",
              "IPY_MODEL_ec18121e45af49038c043411d110adc1",
              "IPY_MODEL_02c83dc6e9024df8acad6804a9833284"
            ],
            "layout": "IPY_MODEL_7ad457413aad41b3a327809198ed4669"
          }
        },
        "30673510b9b942b182b2901176daa2c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a17410ed3aec42668c2a505f1ce275e8",
            "placeholder": "​",
            "style": "IPY_MODEL_50c8fd59e66d44bfa0f15b023331aef4",
            "value": "vocab.txt: "
          }
        },
        "ec18121e45af49038c043411d110adc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9cde3cce10045099c641b2f3f63afaf",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f3707f9f676482ea15e871a5b5a1ad4",
            "value": 1
          }
        },
        "02c83dc6e9024df8acad6804a9833284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e4c7e966af1f40459fd8a9a494e6e0b8",
            "placeholder": "​",
            "style": "IPY_MODEL_192322e577a14456b58bf010720c1fe2",
            "value": " 232k/? [00:00&lt;00:00, 7.40MB/s]"
          }
        },
        "7ad457413aad41b3a327809198ed4669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17410ed3aec42668c2a505f1ce275e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50c8fd59e66d44bfa0f15b023331aef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9cde3cce10045099c641b2f3f63afaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "3f3707f9f676482ea15e871a5b5a1ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e4c7e966af1f40459fd8a9a494e6e0b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192322e577a14456b58bf010720c1fe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec4a95beef9843cf926ee35b61d6cdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9855d530e7a4017bd296845b319416f",
              "IPY_MODEL_af4dcd9d996c43be8448c54c0b101de7",
              "IPY_MODEL_3bfa4da67daf4b9e83842627120253a8"
            ],
            "layout": "IPY_MODEL_56ee3b3fed7c453f8badbd4c5c1de5ec"
          }
        },
        "d9855d530e7a4017bd296845b319416f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_855858e70af545eb86f69137de13f74f",
            "placeholder": "​",
            "style": "IPY_MODEL_85ac9f722b834a15ad46dc50ff34216d",
            "value": "tokenizer.json: "
          }
        },
        "af4dcd9d996c43be8448c54c0b101de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675c3a31b6104766a17a79cbe094b750",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3b0a80fdccf4702911529869258b894",
            "value": 1
          }
        },
        "3bfa4da67daf4b9e83842627120253a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb4d406a6774f79975d30b9a1ccea29",
            "placeholder": "​",
            "style": "IPY_MODEL_8521285e752e4dfaa2920a1f75408e9c",
            "value": " 711k/? [00:00&lt;00:00, 15.0MB/s]"
          }
        },
        "56ee3b3fed7c453f8badbd4c5c1de5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855858e70af545eb86f69137de13f74f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85ac9f722b834a15ad46dc50ff34216d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675c3a31b6104766a17a79cbe094b750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f3b0a80fdccf4702911529869258b894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0fb4d406a6774f79975d30b9a1ccea29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8521285e752e4dfaa2920a1f75408e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab45582549264aadb59f86e1ca07ed0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37bbcb7ac8cd48c6959871850b9f5b76",
              "IPY_MODEL_341e3bbbd3134dfda96b05886c71e156",
              "IPY_MODEL_d75ca3ab1850426097a0be82c01549e6"
            ],
            "layout": "IPY_MODEL_d30d1637157c4bb887fd5a66431b0419"
          }
        },
        "37bbcb7ac8cd48c6959871850b9f5b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_413c60e55945451b9b7479f7b338954e",
            "placeholder": "​",
            "style": "IPY_MODEL_ac039ecee36b450792b7a5165444b91a",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "341e3bbbd3134dfda96b05886c71e156": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83723fe44eb04b3592c3132ffb4c9b60",
            "max": 964,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_74f88ff046fa459d8785310226e88b32",
            "value": 964
          }
        },
        "d75ca3ab1850426097a0be82c01549e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b0c303e23f74939a17fb15d058bb073",
            "placeholder": "​",
            "style": "IPY_MODEL_2f185aa44fec4128b39cc3a98cf0b4e8",
            "value": " 964/964 [00:00&lt;00:00, 102kB/s]"
          }
        },
        "d30d1637157c4bb887fd5a66431b0419": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413c60e55945451b9b7479f7b338954e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac039ecee36b450792b7a5165444b91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83723fe44eb04b3592c3132ffb4c9b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74f88ff046fa459d8785310226e88b32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b0c303e23f74939a17fb15d058bb073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f185aa44fec4128b39cc3a98cf0b4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc348ccf06a2455084bbaff5c580bec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05fa98888cbb47c9b11825057be872ab",
              "IPY_MODEL_60c1426eee914997aa5730f8d883914d",
              "IPY_MODEL_84d480490ae04be39b6ed8f0782a2eeb"
            ],
            "layout": "IPY_MODEL_1d562938e33c45b58d686acb42e3874f"
          }
        },
        "05fa98888cbb47c9b11825057be872ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fcaf2b18905446996addde57f8427f3",
            "placeholder": "​",
            "style": "IPY_MODEL_a01086bb99434e5f9affc18634a4f686",
            "value": "config.json: 100%"
          }
        },
        "60c1426eee914997aa5730f8d883914d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6061a20c45a4672a2178422642dd5a0",
            "max": 698,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f0adfc0eedcd4d699a3fabb65ad77c8b",
            "value": 698
          }
        },
        "84d480490ae04be39b6ed8f0782a2eeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ffc9fcc977194ffc864b27417ecf50ea",
            "placeholder": "​",
            "style": "IPY_MODEL_d84fa2314dba456789451495a56e32dc",
            "value": " 698/698 [00:00&lt;00:00, 84.7kB/s]"
          }
        },
        "1d562938e33c45b58d686acb42e3874f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fcaf2b18905446996addde57f8427f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01086bb99434e5f9affc18634a4f686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6061a20c45a4672a2178422642dd5a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0adfc0eedcd4d699a3fabb65ad77c8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ffc9fcc977194ffc864b27417ecf50ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84fa2314dba456789451495a56e32dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d8adebf34ec4ecd85a75ce3844f8505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f40a55c904d34c8499db4ca517e4619c",
              "IPY_MODEL_23451a5e6217471f975532d88af01278",
              "IPY_MODEL_8f53502f291246e1a4ca4be5939f5346"
            ],
            "layout": "IPY_MODEL_ce3e3665933a43e7a47489fa545be972"
          }
        },
        "f40a55c904d34c8499db4ca517e4619c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d75c7d3da447e7b129c97197171c0a",
            "placeholder": "​",
            "style": "IPY_MODEL_8eeb3df58fb5487093301d61c8ca0b03",
            "value": "model.safetensors: 100%"
          }
        },
        "23451a5e6217471f975532d88af01278": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dc640a051e3b46aeaa99592fcd5b308f",
            "max": 437975200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05be776666ec4fedbd2c15ddeacf8961",
            "value": 437975200
          }
        },
        "8f53502f291246e1a4ca4be5939f5346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7a8725ca88d4ee88003e406295a3671",
            "placeholder": "​",
            "style": "IPY_MODEL_2de08be02a2e44c3b06174771d9809e6",
            "value": " 438M/438M [00:46&lt;00:00, 10.4MB/s]"
          }
        },
        "ce3e3665933a43e7a47489fa545be972": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d75c7d3da447e7b129c97197171c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8eeb3df58fb5487093301d61c8ca0b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc640a051e3b46aeaa99592fcd5b308f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05be776666ec4fedbd2c15ddeacf8961": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7a8725ca88d4ee88003e406295a3671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de08be02a2e44c3b06174771d9809e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashish-Abraham/LLM-Boilerplate/blob/main/ComparisonStudyParaphraser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets==3.6.0 pandas  tqdm"
      ],
      "metadata": {
        "id": "LxD8CKNDlUX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import io\n",
        "import json\n",
        "\n",
        "# ---------------------------\n",
        "# Step 1: Download the dataset\n",
        "# ---------------------------\n",
        "url = \"https://storage.googleapis.com/gresearch/dipper/dipper-training-data.zip\"\n",
        "os.makedirs(\"dipper_data\", exist_ok=True)\n",
        "\n",
        "print(\"Downloading dataset...\")\n",
        "response = requests.get(url)\n",
        "response.raise_for_status()\n",
        "\n",
        "# ---------------------------\n",
        "# Step 2: Extract contents\n",
        "# ---------------------------\n",
        "print(\"Extracting...\")\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    z.extractall(\"dipper_data\")\n",
        "\n",
        "# ---------------------------\n",
        "# Step 3: Inspect top-level folders\n",
        "# ---------------------------\n",
        "for root, dirs, files in os.walk(\"dipper_data\"):\n",
        "    print(root)\n",
        "    # Stop after showing first few paths\n",
        "    if len(dirs) == 0 or \"sents_1\" in root:\n",
        "        break\n",
        "\n",
        "# ---------------------------\n",
        "# Step 4: Find one JSONL file dynamically\n",
        "# ---------------------------\n",
        "jsonl_path = None\n",
        "for root, _, files in os.walk(\"dipper_data\"):\n",
        "    for f in files:\n",
        "        if f.endswith(\".jsonl\"):\n",
        "            jsonl_path = os.path.join(root, f)\n",
        "            break\n",
        "    if jsonl_path:\n",
        "        break\n",
        "\n",
        "if jsonl_path:\n",
        "    print(f\"\\nFound sample file:\\n{jsonl_path}\\n\")\n",
        "\n",
        "    # ---------------------------\n",
        "    # Step 5: Read first few examples\n",
        "    # ---------------------------\n",
        "    with open(jsonl_path, \"r\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            example = json.loads(line)\n",
        "            print(json.dumps(example, indent=2))\n",
        "            if i >= 2:  # show first 3\n",
        "                break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgX_fgLxmE56",
        "outputId": "c79932f0-6f83-4035-8171-10a614610af9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading dataset...\n",
            "Extracting...\n",
            "dipper_data\n",
            "dipper_data/par3\n",
            "dipper_data/par3/gt_translator\n",
            "dipper_data/par3/gt_translator/sents_8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb2345b7",
        "outputId": "d951a44b-214b-49fc-85b9-def83c3fb61f"
      },
      "source": [
        "!apt-get install tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tree\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 47.9 kB of archives.\n",
            "After this operation, 116 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tree amd64 2.0.2-1 [47.9 kB]\n",
            "Fetched 47.9 kB in 1s (42.4 kB/s)\n",
            "Selecting previously unselected package tree.\n",
            "(Reading database ... 126718 files and directories currently installed.)\n",
            "Preparing to unpack .../tree_2.0.2-1_amd64.deb ...\n",
            "Unpacking tree (2.0.2-1) ...\n",
            "Setting up tree (2.0.2-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86f21b7d"
      },
      "source": [
        "!tree /content/dipper_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intel/roberta-base-mrpc"
      ],
      "metadata": {
        "id": "JBsAWWpfaQwE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rcFJ2ZidSHfA",
        "outputId": "8132aff0-0263-46a6-be89-8a4218b2fbda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model/tokenizer: Intel/roberta-base-mrpc ...\n",
            "[load_dipper_val] Searching for DIPPER valid/dev files under: /content/dipper_data\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx.tsv -> 1483\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx.tsv -> 1479\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx.tsv -> 1478\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx.tsv -> 1489\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx.tsv -> 1487\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx.tsv -> 1471\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx.tsv -> 1469\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx.tsv -> 1482\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx.tsv -> 1415\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx.tsv -> 1438\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx.tsv -> 1473\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/ctx_all.tsv\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx.tsv -> 1433\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx.tsv -> 1462\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "[gather_dipper_pos_val] Total valid-like files found: 176\n",
            "[load_dipper_val] Loaded DIPPER val: 8000 samples (label dist: {1: 5327, 0: 2673})\n",
            "Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1325993314.py:170: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n",
            "/tmp/ipython-input-1325993314.py:170: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  HC3 train: no_ctx=60205 ctx=60205\n",
            "Built HC3-eval: 8000 samples\n",
            "Loaded custom CSV: 90 (pos/neg: {1: 60, 0: 30})\n",
            "\n",
            "Evaluating DIPPER_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1325993314.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/roberta_mrpc/dipper_val_confusion_matrix.png\n",
            "Saved /content/output/roberta_mrpc/dipper_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.39      1.00      0.56      2673\n",
            "    Paraphrase       1.00      0.21      0.34      5327\n",
            "\n",
            "      accuracy                           0.47      8000\n",
            "     macro avg       0.69      0.60      0.45      8000\n",
            "  weighted avg       0.79      0.47      0.42      8000\n",
            "\n",
            "\n",
            "Evaluating HC3_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1325993314.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/roberta_mrpc/hc3_val_confusion_matrix.png\n",
            "Saved /content/output/roberta_mrpc/hc3_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.33      1.00      0.50      2664\n",
            "    Paraphrase       1.00      0.00      0.00      5336\n",
            "\n",
            "      accuracy                           0.33      8000\n",
            "     macro avg       0.67      0.50      0.25      8000\n",
            "  weighted avg       0.78      0.33      0.17      8000\n",
            "\n",
            "Saved summary.json to /content/output/roberta_mrpc\n",
            "\n",
            "Evaluating CUSTOM_CSV (90 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1325993314.py:295: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/roberta_mrpc/custom_csv_confusion_matrix.png\n",
            "Saved /content/output/roberta_mrpc/custom_csv_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.78      0.93      0.85        30\n",
            "    Paraphrase       0.96      0.87      0.91        60\n",
            "\n",
            "      accuracy                           0.89        90\n",
            "     macro avg       0.87      0.90      0.88        90\n",
            "  weighted avg       0.90      0.89      0.89        90\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            sentence1  \\\n",
              "0   The possibility of approximating a continuous ...   \n",
              "1   State-of-the-art object detection networks dep...   \n",
              "2   I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "3   Our evolutionary history suggests that there w...   \n",
              "4   The possibility of approximating a continuous ...   \n",
              "..                                                ...   \n",
              "85  The possibility of approximating a continuous ...   \n",
              "86  In fact, science and technology are clearly di...   \n",
              "87  I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "88  Our evolutionary history suggests that there w...   \n",
              "89  We study a novel machine learning (ML) problem...   \n",
              "\n",
              "                                            sentence2  label  pred  \\\n",
              "0   Several studies have examined the ability of a...      1     1   \n",
              "1   Leading object detection networks rely on regi...      1     1   \n",
              "2   I had resolved not to write a \"Top Whatever\" b...      1     0   \n",
              "3   Indeed, science and technology are distinctly ...      0     0   \n",
              "4   Numerous research papers have investigated the...      1     1   \n",
              "..                                                ...    ...   ...   \n",
              "85  A feedforward neural network with one hidden l...      1     1   \n",
              "86  In a recent opinion piece in The Conversation,...      0     0   \n",
              "87  We investigate a new machine learning problem ...      0     0   \n",
              "88  Our evolutionary history indicates that there ...      1     1   \n",
              "89  We investigate a new machine learning problem ...      1     1   \n",
              "\n",
              "    prob_paraphrase  \n",
              "0          0.995276  \n",
              "1          0.995997  \n",
              "2          0.221370  \n",
              "3          0.011346  \n",
              "4          0.996303  \n",
              "..              ...  \n",
              "85         0.996354  \n",
              "86         0.006926  \n",
              "87         0.037536  \n",
              "88         0.996995  \n",
              "89         0.994677  \n",
              "\n",
              "[90 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-45032971-56dc-429d-a862-b0d5ac9243a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_paraphrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Several studies have examined the ability of a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>State-of-the-art object detection networks dep...</td>\n",
              "      <td>Leading object detection networks rely on regi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>I had resolved not to write a \"Top Whatever\" b...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.221370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Indeed, science and technology are distinctly ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.011346</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Numerous research papers have investigated the...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>A feedforward neural network with one hidden l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996354</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>In fact, science and technology are clearly di...</td>\n",
              "      <td>In a recent opinion piece in The Conversation,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006926</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.037536</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Our evolutionary history indicates that there ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>We study a novel machine learning (ML) problem...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.994677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45032971-56dc-429d-a862-b0d5ac9243a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-45032971-56dc-429d-a862-b0d5ac9243a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-45032971-56dc-429d-a862-b0d5ac9243a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a531b483-0e06-4ebd-922c-8df5c4b87baa\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a531b483-0e06-4ebd-922c-8df5c4b87baa')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a531b483-0e06-4ebd-922c-8df5c4b87baa button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"No custom CSV results to display\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Andrew Ng hands me a tiny device that wraps around my ear and connects to a smartphone via a small cable. It looks like a throwback---a smartphone earpiece without a Bluetooth connection. But it's really a glimpse of the future. In a way, this tiny device allows the blind to see.\",\n          \"The possibility of approximating a continuous function on a compact subset of the real line by a feedforward single hidden layer neural network with a sigmoidal activation function has been studied in many papers. \",\n          \"We study a novel machine learning (ML) problem setting of sequentially allocating small subsets of training data amongst a large set of classifiers. The goal is to select a classifier that will give near-optimal accuracy when trained on all data, while also minimizing the cost of misallocated samples.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Several studies have examined the ability of a single hidden layer feedforward neural network with a sigmoidal activation function to approximate a continuous function on a compact subset of the real line.\",\n          \"Professor Lord Krebs stated in a recent opinion article in The Conversation that \\\"accurate reporting of science matters\\\" and that scientists have a professional obligation to \\\"challenge poor media reporting on climate change\\\".\",\n          \"I promise I had no intention of writing a \\\"Top Whatevers of 2015\\\" blog post this year, but then Slate's Benevolent Overlords requested I write one, and what option did I have? They're benevolent, yet they remain overlords. Additionally, I'm fond of them.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_paraphrase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4677982052757374,\n        \"min\": 0.006051229778677225,\n        \"max\": 0.9978844523429871,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.9958935976028442,\n          0.9952763319015503\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved custom_results.csv to /content/output/roberta_mrpc\n"
          ]
        }
      ],
      "source": [
        "# Cell: evaluate Intel/roberta-base-mrpc\n",
        "# Run this cell (requires internet to download HF models & datasets)\n",
        "import os, re, json, math, zipfile, io\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional, Tuple, List\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             matthews_corrcoef, confusion_matrix, roc_auc_score, roc_curve,\n",
        "                             classification_report)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# ----- CONFIG -----\n",
        "MODEL_NAME = \"Intel/roberta-base-mrpc\"\n",
        "OUTPUT_ROOT = Path(\"./output/roberta_mrpc\").resolve()\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_MIXED_PRECISION = True\n",
        "\n",
        "# ----- cleaning/parsing helpers (unchanged except robust column handling) -----\n",
        "def clean_sentence(sent: str) -> str:\n",
        "    s = str(sent)\n",
        "    s = re.sub(r\"lexical\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r\"order\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = s.replace(\"<sent>\", \" \")\n",
        "    # If the cell contains quoted pieces, keep the quoted content (like original code)\n",
        "    matches = re.findall(r'\"([^\"]+)\"', s)\n",
        "    if matches:\n",
        "        s = \" \".join(matches)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.replace(\", ,\", \",\").strip()\n",
        "    return s\n",
        "\n",
        "def parse_dipper_tsv(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Expect at least two columns; some tsvs may have extra columns (we only need first two)\n",
        "    if df is None or df.shape[1] < 2:\n",
        "        return pd.DataFrame(columns=[\"sentence1\", \"sentence2\", \"label\"])\n",
        "    # force using first two columns no matter the header\n",
        "    c1, c2 = df.columns[0], df.columns[1]\n",
        "    s1 = df[c1].astype(str).map(clean_sentence)\n",
        "    s2 = df[c2].astype(str).map(clean_sentence)\n",
        "    out = pd.DataFrame({\"sentence1\": s1, \"sentence2\": s2})\n",
        "    # filter too-short entries (same thresholds as you used)\n",
        "    out = out[(out[\"sentence1\"].str.len() > 8) & (out[\"sentence2\"].str.len() > 8)].copy()\n",
        "    out[\"label\"] = 1\n",
        "    out.dropna(inplace=True)\n",
        "    out.reset_index(drop=True, inplace=True)\n",
        "    return out\n",
        "\n",
        "def _read_tsv(path: str, nrows: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Read a TSV file defensively.\n",
        "    Return DataFrame with whatever columns read (header=None fallback).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # try without header first (most DIPPER tsvs are headerless)\n",
        "        return pd.read_csv(path, sep=\"\\t\", nrows=nrows, header=None, engine=\"python\", quoting=3)\n",
        "    except Exception:\n",
        "        try:\n",
        "            # fallback: let pandas infer header\n",
        "            return pd.read_csv(path, sep=\"\\t\", nrows=nrows, engine=\"python\")\n",
        "        except Exception:\n",
        "            # last resort: return None\n",
        "            return None\n",
        "\n",
        "# ----- New recursive gather function that matches your tree -----\n",
        "def gather_dipper_pos_val(root: str, nrows_val: Optional[int] = 1500) -> List[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Recursively search `root` for any sents_* directories and collect valid/dev-like TSVs.\n",
        "    Returns a list of positive-only DataFrames (label=1).\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    if not os.path.exists(root):\n",
        "        print(f\"[gather_dipper_pos_val] DIPPER root not found: {root}\")\n",
        "        return out\n",
        "\n",
        "    # patterns to accept: valid/dev variants, ctx_all/no_ctx_all variants, and 'valid..._all' etc.\n",
        "    # We'll accept any filename that contains 'valid' or 'dev' or exactly 'ctx_all' / 'no_ctx_all'\n",
        "    # but exclude 'train' files.\n",
        "    def is_valid_file(fname: str) -> bool:\n",
        "        lower = fname.lower()\n",
        "        if \"train\" in lower:\n",
        "            return False\n",
        "        if \"valid\" in lower or \"dev\" in lower or \"ctx_all\" in lower or \"no_ctx_all\" in lower:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    found_files = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        base = os.path.basename(dirpath)\n",
        "        # focus on directories named 'sents_*' (covers the structure you posted)\n",
        "        if not base.startswith(\"sents_\"):\n",
        "            continue\n",
        "        for fname in filenames:\n",
        "            if not fname.lower().endswith(\".tsv\"):\n",
        "                continue\n",
        "            if is_valid_file(fname):\n",
        "                fpath = os.path.join(dirpath, fname)\n",
        "                found_files.append(fpath)\n",
        "                try:\n",
        "                    df_raw = _read_tsv(fpath, nrows=nrows_val)\n",
        "                    df = parse_dipper_tsv(df_raw) if df_raw is not None else None\n",
        "                    if df is not None and len(df) > 0:\n",
        "                        out.append(df)\n",
        "                        print(f\"  ✓ found DIPPER valid-like: {os.path.relpath(fpath, start=root)} -> {len(df)}\")\n",
        "                    else:\n",
        "                        print(f\"  ○ read but no usable rows: {os.path.relpath(fpath, start=root)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  ! failed reading {fpath}: {e}\")\n",
        "\n",
        "    # Also check for some out_domain ctx_all/no_ctx_all files sitting under something like out_domain/*/sents_*\n",
        "    # (the above walk will already hit them because they are under sents_*; this comment is just informative)\n",
        "    if not found_files:\n",
        "        print(f\"[gather_dipper_pos_val] No valid/dev files found under {root}.\")\n",
        "    else:\n",
        "        print(f\"[gather_dipper_pos_val] Total valid-like files found: {len(found_files)}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "# ----- Add negatives (unchanged) -----\n",
        "def add_negatives(df: pd.DataFrame, ratio=1.0, seed=42) -> pd.DataFrame:\n",
        "    pos = df.copy().reset_index(drop=True)\n",
        "    n = len(pos)\n",
        "    if n < 4:\n",
        "        return pos\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(n)\n",
        "    half = n // 2\n",
        "    neg = pd.DataFrame({\n",
        "        \"sentence1\": pos.loc[idx[:half], \"sentence1\"].values,\n",
        "        \"sentence2\": pos.loc[idx[-half:], \"sentence2\"].values,\n",
        "        \"label\": 0\n",
        "    })\n",
        "    if len(neg) > int(len(pos) * ratio):\n",
        "        neg = neg.sample(int(len(pos) * ratio), random_state=seed)\n",
        "    pos[\"label\"] = 1\n",
        "    out = pd.concat([pos, neg], ignore_index=True).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def load_dipper_val(dipper_root: str = \"/content/dipper_data\", val_size_limit: int = 8000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a DIPPER validation DF by aggregating all positive valid-like files found under dipper_root,\n",
        "    then adding negatives and sampling a validation set.\n",
        "    \"\"\"\n",
        "    print(f\"[load_dipper_val] Searching for DIPPER valid/dev files under: {dipper_root}\")\n",
        "    pos_list = gather_dipper_pos_val(dipper_root)\n",
        "    if not pos_list:\n",
        "        raise RuntimeError(\"No DIPPER valid-like files found under dipper_root. Check path and filename conventions.\")\n",
        "    pos_all = pd.concat(pos_list, ignore_index=True)\n",
        "    # deduplicate near-identical pairs (optional): uncomment if needed\n",
        "    # pos_all = pos_all.drop_duplicates(subset=[\"sentence1\",\"sentence2\"]).reset_index(drop=True)\n",
        "    full = add_negatives(pos_all, ratio=1.0)\n",
        "    val_size = min(val_size_limit, max(2000, int(0.1 * len(full))))\n",
        "    val_df = full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[load_dipper_val] Loaded DIPPER val: {len(val_df)} samples (label dist: {val_df['label'].value_counts().to_dict()})\")\n",
        "    return val_df\n",
        "\n",
        "# HC3 helpers (adapted from your code)\n",
        "def to_list_safely(x):\n",
        "    if x is None: return []\n",
        "    try:\n",
        "        if pd.isna(x): return []\n",
        "    except Exception:\n",
        "        pass\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return [str(e).strip() for e in x if str(e).strip()]\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return [str(e).strip() for e in x.tolist() if str(e).strip()]\n",
        "    s = str(x).strip()\n",
        "    return [s] if s else []\n",
        "\n",
        "def make_pairs_from_hc3_split(ds_split, add_context: bool, cartesian: bool = True):\n",
        "    df = ds_split.to_pandas()\n",
        "    rows = []\n",
        "    human_col = \"human_answers\" if \"human_answers\" in df.columns else \"human_answers\"\n",
        "    ai_col = \"chatgpt_answers\" if \"chatgpt_answers\" in df.columns else \"chatgpt_answers\"\n",
        "    q_col = \"question\" if \"question\" in df.columns else None\n",
        "    for _, r in df.iterrows():\n",
        "        q = \"\"\n",
        "        if q_col is not None and q_col in r:\n",
        "            q = str(r[q_col]).strip()\n",
        "        human_list = to_list_safely(r.get(human_col))\n",
        "        ai_list = to_list_safely(r.get(ai_col))\n",
        "        if not human_list or not ai_list:\n",
        "            continue\n",
        "        prefix = \"lexical = NA, order = NA\"\n",
        "        if cartesian:\n",
        "            for h in human_list:\n",
        "                for a in ai_list:\n",
        "                    if add_context and q:\n",
        "                        col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                    else:\n",
        "                        col0 = f\"{prefix} {h}\"\n",
        "                    rows.append((col0, a))\n",
        "        else:\n",
        "            k = min(len(human_list), len(ai_list))\n",
        "            for i in range(k):\n",
        "                h = human_list[i]; a = ai_list[i]\n",
        "                if add_context and q:\n",
        "                    col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                else:\n",
        "                    col0 = f\"{prefix} {h}\"\n",
        "                rows.append((col0, a))\n",
        "    return pd.DataFrame(rows, columns=[0, 1])\n",
        "\n",
        "def build_hc3_tsvs(cartesian=True):\n",
        "    print(\"Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\")\n",
        "    hc3 = load_dataset(\"Hello-SimpleAI/HC3\", \"all\")\n",
        "    all_splits = {}\n",
        "    for split in hc3.keys():\n",
        "        df_no_ctx = make_pairs_from_hc3_split(hc3[split], add_context=False, cartesian=cartesian)\n",
        "        df_no_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_no_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_no_ctx\"] = df_no_ctx\n",
        "        df_ctx = make_pairs_from_hc3_split(hc3[split], add_context=True, cartesian=cartesian)\n",
        "        df_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_ctx\"] = df_ctx\n",
        "        print(f\"  HC3 {split}: no_ctx={len(df_no_ctx)} ctx={len(df_ctx)}\")\n",
        "    # We'll return concatenation of available splits for evaluation\n",
        "    if len(all_splits) == 0:\n",
        "        raise RuntimeError(\"HC3 had no splits.\")\n",
        "    combined = pd.concat(list(all_splits.values()), ignore_index=True)\n",
        "    # Add negatives by shuffling similar to DIPPER\n",
        "    combined_full = add_negatives(combined, ratio=1.0)\n",
        "    # sample validation-size portion (keep reasonable)\n",
        "    val_size = min(8000, max(2000, int(0.1 * len(combined_full))))\n",
        "    val_df = combined_full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"Built HC3-eval: {len(val_df)} samples\")\n",
        "    return val_df\n",
        "\n",
        "# ----- Torch Dataset -----\n",
        "class PairEvalDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_length=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.loc[idx]\n",
        "        a = str(r[\"sentence1\"])\n",
        "        b = str(r[\"sentence2\"])\n",
        "        toks = self.tok(a, b, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in toks.items()}\n",
        "        item[\"label\"] = torch.tensor(int(r[\"label\"]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# ----- Evaluation functions -----\n",
        "def save_confusion_matrix(cm: np.ndarray, dataset_name: str, output_dir: str, normalize: bool = False):\n",
        "    fmt = 'd'\n",
        "    cbar_label = 'Count'\n",
        "    title = f\"{dataset_name} - Confusion Matrix\"\n",
        "    cm_plot = cm\n",
        "    if normalize:\n",
        "        cm_plot = cm.astype(float)\n",
        "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
        "        cm_plot = np.divide(cm_plot, row_sums, where=row_sums != 0)\n",
        "        fmt = '.2f'\n",
        "        cbar_label = 'Proportion'\n",
        "        title = f\"{dataset_name} - Normalized Confusion Matrix\"\n",
        "    plt.figure(figsize=(5.5,4.5))\n",
        "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap='Blues',\n",
        "                xticklabels=['Not Paraphrase','Paraphrase'], yticklabels=['Not Paraphrase','Paraphrase'],\n",
        "                cbar_kws={'label': cbar_label})\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    suffix = '_normalized' if normalize else ''\n",
        "    fname = os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_confusion_matrix{suffix}.png\")\n",
        "    plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {fname}\")\n",
        "\n",
        "def evaluate_and_save(model, tokenizer, df: pd.DataFrame, dataset_name: str, output_dir: str, batch_size: int = 64, device: torch.device = DEVICE):\n",
        "    if df is None or len(df) == 0:\n",
        "        print(f\"Skipping {dataset_name} - no data\")\n",
        "        return None, (None, None)\n",
        "    print(f\"\\nEvaluating {dataset_name} ({len(df)} samples)\")\n",
        "    ds = PairEvalDataset(df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "    model.to(device); model.eval()\n",
        "    all_preds = []; all_labels = []; all_probs = []\n",
        "    use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "    amp_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "    with torch.no_grad():\n",
        "        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n",
        "            for batch in loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                token_type_ids = batch.get('token_type_ids', None)\n",
        "                if token_type_ids is not None:\n",
        "                    token_type_ids = token_type_ids.to(device)\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "                else:\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = out.logits\n",
        "                probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
        "                preds = (probs > 0.5).astype(int)\n",
        "                all_preds.extend(preds.tolist())\n",
        "                all_labels.extend(batch['label'].cpu().numpy().tolist())\n",
        "                all_probs.extend(probs.tolist())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds) if len(set(all_labels))>1 else 0.0\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=[0,1])\n",
        "    auc = None; fpr = None; tpr = None; tpr_1pct = None\n",
        "    try:\n",
        "        auc = float(roc_auc_score(all_labels, all_probs))\n",
        "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "        if len(fpr)>1:\n",
        "            tpr_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "    except Exception:\n",
        "        pass\n",
        "    metrics = {\n",
        "        'dataset': dataset_name,\n",
        "        'accuracy': float(acc),\n",
        "        'precision': float(p),\n",
        "        'recall': float(r),\n",
        "        'f1': float(f1),\n",
        "        'mcc': float(mcc),\n",
        "        'auc': auc,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'samples': len(df),\n",
        "        'tpr_at_1pct_fpr': tpr_1pct,\n",
        "        'fpr': fpr.tolist() if fpr is not None else None,\n",
        "        'tpr': tpr.tolist() if tpr is not None else None\n",
        "    }\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=False)\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=True)\n",
        "    with open(os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_metrics.json\"), \"w\") as fh:\n",
        "        json.dump(metrics, fh, indent=2)\n",
        "    print(classification_report(all_labels, all_preds, target_names=['Not Paraphrase','Paraphrase']))\n",
        "    return metrics, (all_labels, all_probs)\n",
        "\n",
        "# ----- Load model & tokenizer -----\n",
        "print(f\"Loading model/tokenizer: {MODEL_NAME} ...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# ----- Prepare datasets -----\n",
        "try:\n",
        "    dipper_val = load_dipper_val(\"/content/dipper_data\")\n",
        "except Exception as e:\n",
        "    print(\"Warning: DIPPER load failed:\", e)\n",
        "    dipper_val = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "try:\n",
        "    hc3_df = build_hc3_tsvs(cartesian=True)\n",
        "except Exception as e:\n",
        "    print(\"Warning: HC3 load failed:\", e)\n",
        "    hc3_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "# Custom CSV\n",
        "CUSTOM_CSV_PATH = \"/content/custom_paraphrases.csv\"\n",
        "custom_df = None\n",
        "if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "    cdf = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "    if {\"original_sentence\",\"paraphrased_sentence\"}.issubset(set(cdf.columns)):\n",
        "        custom_df = pd.DataFrame({\n",
        "            \"sentence1\": cdf[\"original_sentence\"].astype(str),\n",
        "            \"sentence2\": cdf[\"paraphrased_sentence\"].astype(str),\n",
        "            \"label\": 1\n",
        "        })\n",
        "        custom_eval_df = add_negatives(custom_df, ratio=1.0)\n",
        "        print(f\"Loaded custom CSV: {len(custom_eval_df)} (pos/neg: {custom_eval_df['label'].value_counts().to_dict()})\")\n",
        "    else:\n",
        "        print(\"Custom CSV missing required columns. Skipping custom.\")\n",
        "        custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "else:\n",
        "    print(f\"Custom CSV not found at {CUSTOM_CSV_PATH}. Skipping custom.\")\n",
        "    custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "OUT = OUTPUT_ROOT\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ----- Evaluate DIPPER and HC3 -----\n",
        "all_metrics = []\n",
        "roc_entries = []\n",
        "for df, name in [(dipper_val, \"DIPPER_VAL\"), (hc3_df, \"HC3_VAL\")]:\n",
        "    if df is None or len(df)==0:\n",
        "        print(f\"Skipping {name} - no data\")\n",
        "        continue\n",
        "    metrics, (labels, probs) = evaluate_and_save(model, tokenizer, df, name, str(OUT), batch_size=BATCH_SIZE)\n",
        "    if metrics:\n",
        "        all_metrics.append(metrics)\n",
        "        if metrics.get('auc') is not None and metrics.get('fpr') is not None:\n",
        "            roc_entries.append({\n",
        "                'dataset': name,\n",
        "                'fpr': np.array(metrics['fpr']),\n",
        "                'tpr': np.array(metrics['tpr']),\n",
        "                'auc': metrics['auc'],\n",
        "                'accuracy': metrics['accuracy']\n",
        "            })\n",
        "\n",
        "with open(os.path.join(OUT, \"summary.json\"), \"w\") as fh:\n",
        "    json.dump(all_metrics, fh, indent=2)\n",
        "print(f\"Saved summary.json to {OUT}\")\n",
        "\n",
        "# ----- Plot ROC curves comparison -----\n",
        "if len(roc_entries) > 0:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    cmap = plt.get_cmap('tab10')\n",
        "    lines = []\n",
        "    labels_list = []\n",
        "    for i, entry in enumerate(roc_entries):\n",
        "        color = cmap(i % 10)\n",
        "        fpr = entry['fpr']\n",
        "        tpr = entry['tpr']\n",
        "        auc_val = entry['auc']\n",
        "        acc_val = entry['accuracy']\n",
        "\n",
        "        if len(fpr) == 0 or len(tpr) == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tpr_at_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "        except Exception:\n",
        "            tpr_at_1pct = 0.0\n",
        "        plt.plot(fpr, tpr, label=None, color=color, linewidth=2)\n",
        "        legend_label = f\"{entry['dataset']} (AUC={auc_val:.3f}, TPR@1%FPR={tpr_at_1pct:.3f}, Acc={acc_val:.3f})\"\n",
        "        lines.append(plt.Line2D([0],[0], color=color, lw=2))\n",
        "        labels_list.append(legend_label)\n",
        "\n",
        "    plt.plot([0,1],[0,1], linestyle='--', color='gray', linewidth=1.5, label='Random')\n",
        "    plt.xlim([0.0,1.0])\n",
        "    plt.ylim([0.0,1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(lines + [plt.Line2D([0],[0], color='gray', lw=1.5, linestyle='--')],\n",
        "               labels_list + ['Random'], loc='lower right', fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "    roc_path = os.path.join(OUT, 'roc_comparison.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {roc_path}\")\n",
        "else:\n",
        "    print('No ROC data available for plotting.')\n",
        "\n",
        "# ----- Plot performance metrics comparison -----\n",
        "if len(all_metrics) > 1:\n",
        "    comp_df = pd.DataFrame(all_metrics)\n",
        "    comp_df_sorted = comp_df.set_index('dataset')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    comp_df_sorted[['accuracy','precision','recall','f1','mcc','auc','tpr_at_1pct_fpr']].plot(\n",
        "        kind='bar', ax=ax, width=0.8)\n",
        "    plt.title('Performance Metrics Comparison Across Datasets', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Score', fontsize=12)\n",
        "    plt.xlabel('Dataset', fontsize=12)\n",
        "    plt.ylim(0,1.05)\n",
        "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    comp_path = os.path.join(OUT, 'metrics_comparison.png')\n",
        "    plt.savefig(comp_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {comp_path}\")\n",
        "\n",
        "# ----- Print and save summary table -----\n",
        "summary_df = pd.DataFrame(all_metrics)\n",
        "if not summary_df.empty:\n",
        "    display_cols = ['dataset','accuracy','precision','recall','f1','mcc',\n",
        "                'auc','tpr_at_1pct_fpr','samples']\n",
        "    print('\\n' + '='*80)\n",
        "    print('SUMMARY TABLE')\n",
        "    print('='*80)\n",
        "    print(summary_df[display_cols].round(4).to_string(index=False))\n",
        "    print('='*80)\n",
        "    summary_df.to_csv(os.path.join(OUT, 'summary.csv'), index=False)\n",
        "    print(f\"\\nSaved summary table to {os.path.join(OUT, 'summary.csv')}\")\n",
        "\n",
        "# ----- Evaluate custom CSV and create per-model analysis -----\n",
        "if custom_eval_df is not None and len(custom_eval_df)>0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CUSTOM CSV EVALUATION - PER-MODEL ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    metrics_c, (labels_c, probs_c) = evaluate_and_save(model, tokenizer, custom_eval_df, \"CUSTOM_CSV\", str(OUT), batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Get predictions for all samples\n",
        "    ds_custom = PairEvalDataset(custom_eval_df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds_custom, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    preds_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = F.softmax(out.logits, dim=-1)[:,1].cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            for i in range(len(preds)):\n",
        "                preds_list.append({'pred': int(preds[i]), 'prob_paraphrase': float(probs[i])})\n",
        "\n",
        "    # Combine with original data\n",
        "    report_df = custom_eval_df.copy().reset_index(drop=True)\n",
        "    preds_df = pd.DataFrame(preds_list)\n",
        "    display_df = pd.concat([report_df, preds_df], axis=1)\n",
        "\n",
        "    # Load original CSV to get model names\n",
        "    if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "        orig_csv = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "        if 'model_name' in orig_csv.columns:\n",
        "            display_df['model_name'] = orig_csv['model_name'].values[:len(display_df)]\n",
        "\n",
        "            # Calculate per-model metrics\n",
        "            model_metrics = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                labels_m = model_data['label'].values\n",
        "                preds_m = model_data['pred'].values\n",
        "\n",
        "                acc = accuracy_score(labels_m, preds_m)\n",
        "                p, r, f1, _ = precision_recall_fscore_support(labels_m, preds_m, average='binary', zero_division=0)\n",
        "\n",
        "                model_metrics.append({\n",
        "                    'Model': model_name,\n",
        "                    'Precision (%)': p * 100,\n",
        "                    'Recall (%)': r * 100,\n",
        "                    'F1-Score (%)': f1 * 100,\n",
        "                    'Accuracy (%)': acc * 100,\n",
        "                    'Samples': len(model_data)\n",
        "                })\n",
        "\n",
        "            model_perf_df = pd.DataFrame(model_metrics)\n",
        "\n",
        "            # Display and save per-model table\n",
        "            print(\"\\nPer-Model Performance:\")\n",
        "            print(model_perf_df.round(2).to_string(index=False))\n",
        "            model_perf_df.to_csv(os.path.join(OUT, \"per_model_metrics.csv\"), index=False)\n",
        "            print(f\"\\nSaved per-model metrics to {os.path.join(OUT, 'per_model_metrics.csv')}\")\n",
        "\n",
        "            # Plot per-model performance\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            x = np.arange(len(model_perf_df))\n",
        "            width = 0.2\n",
        "\n",
        "            ax.bar(x - 1.5*width, model_perf_df['Precision (%)'], width, label='Precision', alpha=0.8)\n",
        "            ax.bar(x - 0.5*width, model_perf_df['Recall (%)'], width, label='Recall', alpha=0.8)\n",
        "            ax.bar(x + 0.5*width, model_perf_df['F1-Score (%)'], width, label='F1-Score', alpha=0.8)\n",
        "            ax.bar(x + 1.5*width, model_perf_df['Accuracy (%)'], width, label='Accuracy', alpha=0.8)\n",
        "\n",
        "            ax.set_ylabel('Score (%)', fontsize=12)\n",
        "            ax.set_xlabel('Model', fontsize=12)\n",
        "            ax.set_title('Paraphrase Detection Performance by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(model_perf_df['Model'], rotation=45, ha='right')\n",
        "            ax.legend()\n",
        "            ax.set_ylim(0, 105)\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            model_plot_path = os.path.join(OUT, 'per_model_performance.png')\n",
        "            plt.savefig(model_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved per-model plot to {model_plot_path}\")\n",
        "\n",
        "            # Plot average probability scores by model\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            model_probs = display_df.groupby('model_name')['prob_paraphrase'].agg(['mean', 'std'])\n",
        "            model_probs = model_probs.sort_values('mean', ascending=False)\n",
        "\n",
        "            ax.barh(model_probs.index, model_probs['mean'], xerr=model_probs['std'],\n",
        "                   capsize=5, alpha=0.7, color='steelblue')\n",
        "            ax.set_xlabel('Average Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Model', fontsize=12)\n",
        "            ax.set_title('Average Paraphrase Detection Confidence by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.grid(axis='x', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            prob_plot_path = os.path.join(OUT, 'model_confidence_scores.png')\n",
        "            plt.savefig(prob_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence scores plot to {prob_plot_path}\")\n",
        "\n",
        "            # Heatmap of per-model confusion matrices\n",
        "            n_models = len(model_perf_df)\n",
        "            fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
        "            if n_models == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            for idx, model_name in enumerate(display_df['model_name'].unique()):\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                cm = confusion_matrix(model_data['label'], model_data['pred'], labels=[0,1])\n",
        "\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                           xticklabels=['Not Para','Para'],\n",
        "                           yticklabels=['Not Para','Para'],\n",
        "                           cbar=False)\n",
        "                axes[idx].set_title(f'{model_name}', fontsize=11, fontweight='bold')\n",
        "                axes[idx].set_ylabel('True' if idx == 0 else '', fontsize=10)\n",
        "                axes[idx].set_xlabel('Predicted', fontsize=10)\n",
        "\n",
        "            plt.suptitle('Confusion Matrices by LLM', fontsize=14, fontweight='bold', y=1.02)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            cm_plot_path = os.path.join(OUT, 'model_confusion_matrices.png')\n",
        "            plt.savefig(cm_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confusion matrices plot to {cm_plot_path}\")\n",
        "\n",
        "            # Create error analysis: false positives and false negatives by model\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "            error_data = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                fp = ((model_data['label'] == 0) & (model_data['pred'] == 1)).sum()\n",
        "                fn = ((model_data['label'] == 1) & (model_data['pred'] == 0)).sum()\n",
        "                tp = ((model_data['label'] == 1) & (model_data['pred'] == 1)).sum()\n",
        "                tn = ((model_data['label'] == 0) & (model_data['pred'] == 0)).sum()\n",
        "                error_data.append({\n",
        "                    'Model': model_name,\n",
        "                    'False Positives': fp,\n",
        "                    'False Negatives': fn,\n",
        "                    'True Positives': tp,\n",
        "                    'True Negatives': tn\n",
        "                })\n",
        "\n",
        "            error_df = pd.DataFrame(error_data)\n",
        "\n",
        "            # Plot false positives and false negatives\n",
        "            x = np.arange(len(error_df))\n",
        "            width = 0.35\n",
        "\n",
        "            ax1.bar(x - width/2, error_df['False Positives'], width, label='False Positives', color='salmon', alpha=0.8)\n",
        "            ax1.bar(x + width/2, error_df['False Negatives'], width, label='False Negatives', color='lightcoral', alpha=0.8)\n",
        "            ax1.set_ylabel('Count', fontsize=11)\n",
        "            ax1.set_xlabel('Model', fontsize=11)\n",
        "            ax1.set_title('Error Analysis: False Positives vs False Negatives', fontsize=12, fontweight='bold')\n",
        "            ax1.set_xticks(x)\n",
        "            ax1.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax1.legend()\n",
        "            ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            # Plot true positives and true negatives\n",
        "            ax2.bar(x - width/2, error_df['True Positives'], width, label='True Positives', color='mediumseagreen', alpha=0.8)\n",
        "            ax2.bar(x + width/2, error_df['True Negatives'], width, label='True Negatives', color='lightgreen', alpha=0.8)\n",
        "            ax2.set_ylabel('Count', fontsize=11)\n",
        "            ax2.set_xlabel('Model', fontsize=11)\n",
        "            ax2.set_title('Correct Predictions: True Positives vs True Negatives', fontsize=12, fontweight='bold')\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax2.legend()\n",
        "            ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            error_plot_path = os.path.join(OUT, 'model_error_analysis.png')\n",
        "            plt.savefig(error_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved error analysis plot to {error_plot_path}\")\n",
        "\n",
        "            # Distribution of confidence scores by model\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                ax.hist(model_data['prob_paraphrase'], bins=30, alpha=0.5, label=model_name, edgecolor='black')\n",
        "\n",
        "            ax.set_xlabel('Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Frequency', fontsize=12)\n",
        "            ax.set_title('Distribution of Paraphrase Detection Confidence Scores by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            ax.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            dist_plot_path = os.path.join(OUT, 'confidence_distribution.png')\n",
        "            plt.savefig(dist_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence distribution plot to {dist_plot_path}\")\n",
        "\n",
        "    # Save detailed per-sample results\n",
        "    display_df.to_csv(os.path.join(OUT, \"custom_results_detailed.csv\"), index=False)\n",
        "    print(f\"\\nSaved detailed results to {os.path.join(OUT, 'custom_results_detailed.csv')}\")\n",
        "    print(f\"Total samples evaluated: {len(display_df)}\")\n",
        "else:\n",
        "    print(\"\\nNo custom CSV results to display.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"All results saved to: {OUT}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  - summary.json, summary.csv: Overall metrics across datasets\")\n",
        "print(\"  - roc_comparison.png: ROC curves for DIPPER and HC3\")\n",
        "print(\"  - metrics_comparison.png: Bar chart comparing all metrics\")\n",
        "print(\"  - per_model_metrics.csv: Performance table by LLM\")\n",
        "print(\"  - per_model_performance.png: Bar chart of metrics by LLM\")\n",
        "print(\"  - model_confidence_scores.png: Average confidence by LLM\")\n",
        "print(\"  - model_confusion_matrices.png: Confusion matrices grid\")\n",
        "print(\"  - model_error_analysis.png: False positive/negative analysis\")\n",
        "print(\"  - confidence_distribution.png: Probability distributions\")\n",
        "print(\"  - custom_results_detailed.csv: Per-sample predictions\")\n",
        "print(\"=\"*80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intel/bert-base-uncased-mrpc"
      ],
      "metadata": {
        "id": "9NwVFdxraYWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "# Delete model, tokenizer, and any large tensors\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "nSOHGrUCw1JO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell: evaluate Intel/bert-base-uncased-mrpc\n",
        "import os, re, json, zipfile, io\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from typing import Optional, List\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                             matthews_corrcoef, confusion_matrix, roc_auc_score, roc_curve,\n",
        "                             classification_report)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "MODEL_NAME = \"Intel/bert-base-uncased-mrpc\"\n",
        "OUTPUT_ROOT = Path(\"./output/bert_mrpc\").resolve()\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_MIXED_PRECISION = True\n",
        "\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_MIXED_PRECISION = True\n",
        "\n",
        "# ----- cleaning/parsing helpers (unchanged except robust column handling) -----\n",
        "def clean_sentence(sent: str) -> str:\n",
        "    s = str(sent)\n",
        "    s = re.sub(r\"lexical\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r\"order\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = s.replace(\"<sent>\", \" \")\n",
        "    # If the cell contains quoted pieces, keep the quoted content (like original code)\n",
        "    matches = re.findall(r'\"([^\"]+)\"', s)\n",
        "    if matches:\n",
        "        s = \" \".join(matches)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.replace(\", ,\", \",\").strip()\n",
        "    return s\n",
        "\n",
        "def parse_dipper_tsv(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Expect at least two columns; some tsvs may have extra columns (we only need first two)\n",
        "    if df is None or df.shape[1] < 2:\n",
        "        return pd.DataFrame(columns=[\"sentence1\", \"sentence2\", \"label\"])\n",
        "    # force using first two columns no matter the header\n",
        "    c1, c2 = df.columns[0], df.columns[1]\n",
        "    s1 = df[c1].astype(str).map(clean_sentence)\n",
        "    s2 = df[c2].astype(str).map(clean_sentence)\n",
        "    out = pd.DataFrame({\"sentence1\": s1, \"sentence2\": s2})\n",
        "    # filter too-short entries (same thresholds as you used)\n",
        "    out = out[(out[\"sentence1\"].str.len() > 8) & (out[\"sentence2\"].str.len() > 8)].copy()\n",
        "    out[\"label\"] = 1\n",
        "    out.dropna(inplace=True)\n",
        "    out.reset_index(drop=True, inplace=True)\n",
        "    return out\n",
        "\n",
        "def _read_tsv(path: str, nrows: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Read a TSV file defensively.\n",
        "    Return DataFrame with whatever columns read (header=None fallback).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # try without header first (most DIPPER tsvs are headerless)\n",
        "        return pd.read_csv(path, sep=\"\\t\", nrows=nrows, header=None, engine=\"python\", quoting=3)\n",
        "    except Exception:\n",
        "        try:\n",
        "            # fallback: let pandas infer header\n",
        "            return pd.read_csv(path, sep=\"\\t\", nrows=nrows, engine=\"python\")\n",
        "        except Exception:\n",
        "            # last resort: return None\n",
        "            return None\n",
        "\n",
        "# ----- New recursive gather function that matches your tree -----\n",
        "def gather_dipper_pos_val(root: str, nrows_val: Optional[int] = 1500) -> List[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Recursively search `root` for any sents_* directories and collect valid/dev-like TSVs.\n",
        "    Returns a list of positive-only DataFrames (label=1).\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    if not os.path.exists(root):\n",
        "        print(f\"[gather_dipper_pos_val] DIPPER root not found: {root}\")\n",
        "        return out\n",
        "\n",
        "    # patterns to accept: valid/dev variants, ctx_all/no_ctx_all variants, and 'valid..._all' etc.\n",
        "    # We'll accept any filename that contains 'valid' or 'dev' or exactly 'ctx_all' / 'no_ctx_all'\n",
        "    # but exclude 'train' files.\n",
        "    def is_valid_file(fname: str) -> bool:\n",
        "        lower = fname.lower()\n",
        "        if \"train\" in lower:\n",
        "            return False\n",
        "        if \"valid\" in lower or \"dev\" in lower or \"ctx_all\" in lower or \"no_ctx_all\" in lower:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    found_files = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        base = os.path.basename(dirpath)\n",
        "        # focus on directories named 'sents_*' (covers the structure you posted)\n",
        "        if not base.startswith(\"sents_\"):\n",
        "            continue\n",
        "        for fname in filenames:\n",
        "            if not fname.lower().endswith(\".tsv\"):\n",
        "                continue\n",
        "            if is_valid_file(fname):\n",
        "                fpath = os.path.join(dirpath, fname)\n",
        "                found_files.append(fpath)\n",
        "                try:\n",
        "                    df_raw = _read_tsv(fpath, nrows=nrows_val)\n",
        "                    df = parse_dipper_tsv(df_raw) if df_raw is not None else None\n",
        "                    if df is not None and len(df) > 0:\n",
        "                        out.append(df)\n",
        "                        print(f\"  ✓ found DIPPER valid-like: {os.path.relpath(fpath, start=root)} -> {len(df)}\")\n",
        "                    else:\n",
        "                        print(f\"  ○ read but no usable rows: {os.path.relpath(fpath, start=root)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  ! failed reading {fpath}: {e}\")\n",
        "\n",
        "    # Also check for some out_domain ctx_all/no_ctx_all files sitting under something like out_domain/*/sents_*\n",
        "    # (the above walk will already hit them because they are under sents_*; this comment is just informative)\n",
        "    if not found_files:\n",
        "        print(f\"[gather_dipper_pos_val] No valid/dev files found under {root}.\")\n",
        "    else:\n",
        "        print(f\"[gather_dipper_pos_val] Total valid-like files found: {len(found_files)}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "# ----- Add negatives (unchanged) -----\n",
        "def add_negatives(df: pd.DataFrame, ratio=1.0, seed=42) -> pd.DataFrame:\n",
        "    pos = df.copy().reset_index(drop=True)\n",
        "    n = len(pos)\n",
        "    if n < 4:\n",
        "        return pos\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(n)\n",
        "    half = n // 2\n",
        "    neg = pd.DataFrame({\n",
        "        \"sentence1\": pos.loc[idx[:half], \"sentence1\"].values,\n",
        "        \"sentence2\": pos.loc[idx[-half:], \"sentence2\"].values,\n",
        "        \"label\": 0\n",
        "    })\n",
        "    if len(neg) > int(len(pos) * ratio):\n",
        "        neg = neg.sample(int(len(pos) * ratio), random_state=seed)\n",
        "    pos[\"label\"] = 1\n",
        "    out = pd.concat([pos, neg], ignore_index=True).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def load_dipper_val(dipper_root: str = \"/content/dipper_data\", val_size_limit: int = 8000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a DIPPER validation DF by aggregating all positive valid-like files found under dipper_root,\n",
        "    then adding negatives and sampling a validation set.\n",
        "    \"\"\"\n",
        "    print(f\"[load_dipper_val] Searching for DIPPER valid/dev files under: {dipper_root}\")\n",
        "    pos_list = gather_dipper_pos_val(dipper_root)\n",
        "    if not pos_list:\n",
        "        raise RuntimeError(\"No DIPPER valid-like files found under dipper_root. Check path and filename conventions.\")\n",
        "    pos_all = pd.concat(pos_list, ignore_index=True)\n",
        "    # deduplicate near-identical pairs (optional): uncomment if needed\n",
        "    # pos_all = pos_all.drop_duplicates(subset=[\"sentence1\",\"sentence2\"]).reset_index(drop=True)\n",
        "    full = add_negatives(pos_all, ratio=1.0)\n",
        "    val_size = min(val_size_limit, max(2000, int(0.1 * len(full))))\n",
        "    val_df = full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[load_dipper_val] Loaded DIPPER val: {len(val_df)} samples (label dist: {val_df['label'].value_counts().to_dict()})\")\n",
        "    return val_df\n",
        "\n",
        "# HC3 helpers (adapted from your code)\n",
        "def to_list_safely(x):\n",
        "    if x is None: return []\n",
        "    try:\n",
        "        if pd.isna(x): return []\n",
        "    except Exception:\n",
        "        pass\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return [str(e).strip() for e in x if str(e).strip()]\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return [str(e).strip() for e in x.tolist() if str(e).strip()]\n",
        "    s = str(x).strip()\n",
        "    return [s] if s else []\n",
        "\n",
        "def make_pairs_from_hc3_split(ds_split, add_context: bool, cartesian: bool = True):\n",
        "    df = ds_split.to_pandas()\n",
        "    rows = []\n",
        "    human_col = \"human_answers\" if \"human_answers\" in df.columns else \"human_answers\"\n",
        "    ai_col = \"chatgpt_answers\" if \"chatgpt_answers\" in df.columns else \"chatgpt_answers\"\n",
        "    q_col = \"question\" if \"question\" in df.columns else None\n",
        "    for _, r in df.iterrows():\n",
        "        q = \"\"\n",
        "        if q_col is not None and q_col in r:\n",
        "            q = str(r[q_col]).strip()\n",
        "        human_list = to_list_safely(r.get(human_col))\n",
        "        ai_list = to_list_safely(r.get(ai_col))\n",
        "        if not human_list or not ai_list:\n",
        "            continue\n",
        "        prefix = \"lexical = NA, order = NA\"\n",
        "        if cartesian:\n",
        "            for h in human_list:\n",
        "                for a in ai_list:\n",
        "                    if add_context and q:\n",
        "                        col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                    else:\n",
        "                        col0 = f\"{prefix} {h}\"\n",
        "                    rows.append((col0, a))\n",
        "        else:\n",
        "            k = min(len(human_list), len(ai_list))\n",
        "            for i in range(k):\n",
        "                h = human_list[i]; a = ai_list[i]\n",
        "                if add_context and q:\n",
        "                    col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                else:\n",
        "                    col0 = f\"{prefix} {h}\"\n",
        "                rows.append((col0, a))\n",
        "    return pd.DataFrame(rows, columns=[0, 1])\n",
        "\n",
        "def build_hc3_tsvs(cartesian=True):\n",
        "    print(\"Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\")\n",
        "    hc3 = load_dataset(\"Hello-SimpleAI/HC3\", \"all\")\n",
        "    all_splits = {}\n",
        "    for split in hc3.keys():\n",
        "        df_no_ctx = make_pairs_from_hc3_split(hc3[split], add_context=False, cartesian=cartesian)\n",
        "        df_no_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_no_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_no_ctx\"] = df_no_ctx\n",
        "        df_ctx = make_pairs_from_hc3_split(hc3[split], add_context=True, cartesian=cartesian)\n",
        "        df_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_ctx\"] = df_ctx\n",
        "        print(f\"  HC3 {split}: no_ctx={len(df_no_ctx)} ctx={len(df_ctx)}\")\n",
        "    # We'll return concatenation of available splits for evaluation\n",
        "    if len(all_splits) == 0:\n",
        "        raise RuntimeError(\"HC3 had no splits.\")\n",
        "    combined = pd.concat(list(all_splits.values()), ignore_index=True)\n",
        "    # Add negatives by shuffling similar to DIPPER\n",
        "    combined_full = add_negatives(combined, ratio=1.0)\n",
        "    # sample validation-size portion (keep reasonable)\n",
        "    val_size = min(8000, max(2000, int(0.1 * len(combined_full))))\n",
        "    val_df = combined_full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"Built HC3-eval: {len(val_df)} samples\")\n",
        "    return val_df\n",
        "\n",
        "# ----- Torch Dataset -----\n",
        "class PairEvalDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_length=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.loc[idx]\n",
        "        a = str(r[\"sentence1\"])\n",
        "        b = str(r[\"sentence2\"])\n",
        "        toks = self.tok(a, b, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in toks.items()}\n",
        "        item[\"label\"] = torch.tensor(int(r[\"label\"]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# ----- Evaluation functions -----\n",
        "def save_confusion_matrix(cm: np.ndarray, dataset_name: str, output_dir: str, normalize: bool = False):\n",
        "    fmt = 'd'\n",
        "    cbar_label = 'Count'\n",
        "    title = f\"{dataset_name} - Confusion Matrix\"\n",
        "    cm_plot = cm\n",
        "    if normalize:\n",
        "        cm_plot = cm.astype(float)\n",
        "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
        "        cm_plot = np.divide(cm_plot, row_sums, where=row_sums != 0)\n",
        "        fmt = '.2f'\n",
        "        cbar_label = 'Proportion'\n",
        "        title = f\"{dataset_name} - Normalized Confusion Matrix\"\n",
        "    plt.figure(figsize=(5.5,4.5))\n",
        "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap='Blues',\n",
        "                xticklabels=['Not Paraphrase','Paraphrase'], yticklabels=['Not Paraphrase','Paraphrase'],\n",
        "                cbar_kws={'label': cbar_label})\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    suffix = '_normalized' if normalize else ''\n",
        "    fname = os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_confusion_matrix{suffix}.png\")\n",
        "    plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {fname}\")\n",
        "\n",
        "def evaluate_and_save(model, tokenizer, df: pd.DataFrame, dataset_name: str, output_dir: str, batch_size: int = 64, device: torch.device = DEVICE):\n",
        "    if df is None or len(df) == 0:\n",
        "        print(f\"Skipping {dataset_name} - no data\")\n",
        "        return None, (None, None)\n",
        "    print(f\"\\nEvaluating {dataset_name} ({len(df)} samples)\")\n",
        "    ds = PairEvalDataset(df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "    model.to(device); model.eval()\n",
        "    all_preds = []; all_labels = []; all_probs = []\n",
        "    use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "    amp_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "    with torch.no_grad():\n",
        "        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n",
        "            for batch in loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                token_type_ids = batch.get('token_type_ids', None)\n",
        "                if token_type_ids is not None:\n",
        "                    token_type_ids = token_type_ids.to(device)\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "                else:\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = out.logits\n",
        "                probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
        "                preds = (probs > 0.5).astype(int)\n",
        "                all_preds.extend(preds.tolist())\n",
        "                all_labels.extend(batch['label'].cpu().numpy().tolist())\n",
        "                all_probs.extend(probs.tolist())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds) if len(set(all_labels))>1 else 0.0\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=[0,1])\n",
        "    auc = None; fpr = None; tpr = None; tpr_1pct = None\n",
        "    try:\n",
        "        auc = float(roc_auc_score(all_labels, all_probs))\n",
        "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "        if len(fpr)>1:\n",
        "            tpr_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "    except Exception:\n",
        "        pass\n",
        "    metrics = {\n",
        "        'dataset': dataset_name,\n",
        "        'accuracy': float(acc),\n",
        "        'precision': float(p),\n",
        "        'recall': float(r),\n",
        "        'f1': float(f1),\n",
        "        'mcc': float(mcc),\n",
        "        'auc': auc,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'samples': len(df),\n",
        "        'tpr_at_1pct_fpr': tpr_1pct,\n",
        "        'fpr': fpr.tolist() if fpr is not None else None,\n",
        "        'tpr': tpr.tolist() if tpr is not None else None\n",
        "    }\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=False)\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=True)\n",
        "    with open(os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_metrics.json\"), \"w\") as fh:\n",
        "        json.dump(metrics, fh, indent=2)\n",
        "    print(classification_report(all_labels, all_preds, target_names=['Not Paraphrase','Paraphrase']))\n",
        "    return metrics, (all_labels, all_probs)\n",
        "\n",
        "# ----- Load model & tokenizer -----\n",
        "print(f\"Loading model/tokenizer: {MODEL_NAME} ...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# ----- Prepare datasets -----\n",
        "try:\n",
        "    dipper_val = load_dipper_val(\"/content/dipper_data\")\n",
        "except Exception as e:\n",
        "    print(\"Warning: DIPPER load failed:\", e)\n",
        "    dipper_val = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "try:\n",
        "    hc3_df = build_hc3_tsvs(cartesian=True)\n",
        "except Exception as e:\n",
        "    print(\"Warning: HC3 load failed:\", e)\n",
        "    hc3_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "# Custom CSV\n",
        "CUSTOM_CSV_PATH = \"/content/custom_paraphrases.csv\"\n",
        "custom_df = None\n",
        "if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "    cdf = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "    if {\"original_sentence\",\"paraphrased_sentence\"}.issubset(set(cdf.columns)):\n",
        "        custom_df = pd.DataFrame({\n",
        "            \"sentence1\": cdf[\"original_sentence\"].astype(str),\n",
        "            \"sentence2\": cdf[\"paraphrased_sentence\"].astype(str),\n",
        "            \"label\": 1\n",
        "        })\n",
        "        custom_eval_df = add_negatives(custom_df, ratio=1.0)\n",
        "        print(f\"Loaded custom CSV: {len(custom_eval_df)} (pos/neg: {custom_eval_df['label'].value_counts().to_dict()})\")\n",
        "    else:\n",
        "        print(\"Custom CSV missing required columns. Skipping custom.\")\n",
        "        custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "else:\n",
        "    print(f\"Custom CSV not found at {CUSTOM_CSV_PATH}. Skipping custom.\")\n",
        "    custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "OUT = OUTPUT_ROOT\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ----- Evaluate DIPPER and HC3 -----\n",
        "all_metrics = []\n",
        "roc_entries = []\n",
        "for df, name in [(dipper_val, \"DIPPER_VAL\"), (hc3_df, \"HC3_VAL\")]:\n",
        "    if df is None or len(df)==0:\n",
        "        print(f\"Skipping {name} - no data\")\n",
        "        continue\n",
        "    metrics, (labels, probs) = evaluate_and_save(model, tokenizer, df, name, str(OUT), batch_size=BATCH_SIZE)\n",
        "    if metrics:\n",
        "        all_metrics.append(metrics)\n",
        "        if metrics.get('auc') is not None and metrics.get('fpr') is not None:\n",
        "            roc_entries.append({\n",
        "                'dataset': name,\n",
        "                'fpr': np.array(metrics['fpr']),\n",
        "                'tpr': np.array(metrics['tpr']),\n",
        "                'auc': metrics['auc'],\n",
        "                'accuracy': metrics['accuracy']\n",
        "            })\n",
        "\n",
        "with open(os.path.join(OUT, \"summary.json\"), \"w\") as fh:\n",
        "    json.dump(all_metrics, fh, indent=2)\n",
        "print(f\"Saved summary.json to {OUT}\")\n",
        "\n",
        "# ----- Plot ROC curves comparison -----\n",
        "if len(roc_entries) > 0:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    cmap = plt.get_cmap('tab10')\n",
        "    lines = []\n",
        "    labels_list = []\n",
        "    for i, entry in enumerate(roc_entries):\n",
        "        color = cmap(i % 10)\n",
        "        fpr = entry['fpr']\n",
        "        tpr = entry['tpr']\n",
        "        auc_val = entry['auc']\n",
        "        acc_val = entry['accuracy']\n",
        "\n",
        "        if len(fpr) == 0 or len(tpr) == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tpr_at_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "        except Exception:\n",
        "            tpr_at_1pct = 0.0\n",
        "        plt.plot(fpr, tpr, label=None, color=color, linewidth=2)\n",
        "        legend_label = f\"{entry['dataset']} (AUC={auc_val:.3f}, TPR@1%FPR={tpr_at_1pct:.3f}, Acc={acc_val:.3f})\"\n",
        "        lines.append(plt.Line2D([0],[0], color=color, lw=2))\n",
        "        labels_list.append(legend_label)\n",
        "\n",
        "    plt.plot([0,1],[0,1], linestyle='--', color='gray', linewidth=1.5, label='Random')\n",
        "    plt.xlim([0.0,1.0])\n",
        "    plt.ylim([0.0,1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(lines + [plt.Line2D([0],[0], color='gray', lw=1.5, linestyle='--')],\n",
        "               labels_list + ['Random'], loc='lower right', fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "    roc_path = os.path.join(OUT, 'roc_comparison.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {roc_path}\")\n",
        "else:\n",
        "    print('No ROC data available for plotting.')\n",
        "\n",
        "# ----- Plot performance metrics comparison -----\n",
        "if len(all_metrics) > 1:\n",
        "    comp_df = pd.DataFrame(all_metrics)\n",
        "    comp_df_sorted = comp_df.set_index('dataset')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    comp_df_sorted[['accuracy','precision','recall','f1','mcc','auc','tpr_at_1pct_fpr']].plot(\n",
        "        kind='bar', ax=ax, width=0.8)\n",
        "    plt.title('Performance Metrics Comparison Across Datasets', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Score', fontsize=12)\n",
        "    plt.xlabel('Dataset', fontsize=12)\n",
        "    plt.ylim(0,1.05)\n",
        "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    comp_path = os.path.join(OUT, 'metrics_comparison.png')\n",
        "    plt.savefig(comp_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {comp_path}\")\n",
        "\n",
        "# ----- Print and save summary table -----\n",
        "summary_df = pd.DataFrame(all_metrics)\n",
        "if not summary_df.empty:\n",
        "    display_cols = ['dataset','accuracy','precision','recall','f1','mcc',\n",
        "                'auc','tpr_at_1pct_fpr','samples']\n",
        "    print('\\n' + '='*80)\n",
        "    print('SUMMARY TABLE')\n",
        "    print('='*80)\n",
        "    print(summary_df[display_cols].round(4).to_string(index=False))\n",
        "    print('='*80)\n",
        "    summary_df.to_csv(os.path.join(OUT, 'summary.csv'), index=False)\n",
        "    print(f\"\\nSaved summary table to {os.path.join(OUT, 'summary.csv')}\")\n",
        "\n",
        "# ----- Evaluate custom CSV and create per-model analysis -----\n",
        "if custom_eval_df is not None and len(custom_eval_df)>0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CUSTOM CSV EVALUATION - PER-MODEL ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    metrics_c, (labels_c, probs_c) = evaluate_and_save(model, tokenizer, custom_eval_df, \"CUSTOM_CSV\", str(OUT), batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Get predictions for all samples\n",
        "    ds_custom = PairEvalDataset(custom_eval_df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds_custom, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    preds_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = F.softmax(out.logits, dim=-1)[:,1].cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            for i in range(len(preds)):\n",
        "                preds_list.append({'pred': int(preds[i]), 'prob_paraphrase': float(probs[i])})\n",
        "\n",
        "    # Combine with original data\n",
        "    report_df = custom_eval_df.copy().reset_index(drop=True)\n",
        "    preds_df = pd.DataFrame(preds_list)\n",
        "    display_df = pd.concat([report_df, preds_df], axis=1)\n",
        "\n",
        "    # Load original CSV to get model names\n",
        "    if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "        orig_csv = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "        if 'model_name' in orig_csv.columns:\n",
        "            display_df['model_name'] = orig_csv['model_name'].values[:len(display_df)]\n",
        "\n",
        "            # Calculate per-model metrics\n",
        "            model_metrics = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                labels_m = model_data['label'].values\n",
        "                preds_m = model_data['pred'].values\n",
        "\n",
        "                acc = accuracy_score(labels_m, preds_m)\n",
        "                p, r, f1, _ = precision_recall_fscore_support(labels_m, preds_m, average='binary', zero_division=0)\n",
        "\n",
        "                model_metrics.append({\n",
        "                    'Model': model_name,\n",
        "                    'Precision (%)': p * 100,\n",
        "                    'Recall (%)': r * 100,\n",
        "                    'F1-Score (%)': f1 * 100,\n",
        "                    'Accuracy (%)': acc * 100,\n",
        "                    'Samples': len(model_data)\n",
        "                })\n",
        "\n",
        "            model_perf_df = pd.DataFrame(model_metrics)\n",
        "\n",
        "            # Display and save per-model table\n",
        "            print(\"\\nPer-Model Performance:\")\n",
        "            print(model_perf_df.round(2).to_string(index=False))\n",
        "            model_perf_df.to_csv(os.path.join(OUT, \"per_model_metrics.csv\"), index=False)\n",
        "            print(f\"\\nSaved per-model metrics to {os.path.join(OUT, 'per_model_metrics.csv')}\")\n",
        "\n",
        "            # Plot per-model performance\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            x = np.arange(len(model_perf_df))\n",
        "            width = 0.2\n",
        "\n",
        "            ax.bar(x - 1.5*width, model_perf_df['Precision (%)'], width, label='Precision', alpha=0.8)\n",
        "            ax.bar(x - 0.5*width, model_perf_df['Recall (%)'], width, label='Recall', alpha=0.8)\n",
        "            ax.bar(x + 0.5*width, model_perf_df['F1-Score (%)'], width, label='F1-Score', alpha=0.8)\n",
        "            ax.bar(x + 1.5*width, model_perf_df['Accuracy (%)'], width, label='Accuracy', alpha=0.8)\n",
        "\n",
        "            ax.set_ylabel('Score (%)', fontsize=12)\n",
        "            ax.set_xlabel('Model', fontsize=12)\n",
        "            ax.set_title('Paraphrase Detection Performance by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(model_perf_df['Model'], rotation=45, ha='right')\n",
        "            ax.legend()\n",
        "            ax.set_ylim(0, 105)\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            model_plot_path = os.path.join(OUT, 'per_model_performance.png')\n",
        "            plt.savefig(model_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved per-model plot to {model_plot_path}\")\n",
        "\n",
        "            # Plot average probability scores by model\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            model_probs = display_df.groupby('model_name')['prob_paraphrase'].agg(['mean', 'std'])\n",
        "            model_probs = model_probs.sort_values('mean', ascending=False)\n",
        "\n",
        "            ax.barh(model_probs.index, model_probs['mean'], xerr=model_probs['std'],\n",
        "                   capsize=5, alpha=0.7, color='steelblue')\n",
        "            ax.set_xlabel('Average Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Model', fontsize=12)\n",
        "            ax.set_title('Average Paraphrase Detection Confidence by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.grid(axis='x', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            prob_plot_path = os.path.join(OUT, 'model_confidence_scores.png')\n",
        "            plt.savefig(prob_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence scores plot to {prob_plot_path}\")\n",
        "\n",
        "            # Heatmap of per-model confusion matrices\n",
        "            n_models = len(model_perf_df)\n",
        "            fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
        "            if n_models == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            for idx, model_name in enumerate(display_df['model_name'].unique()):\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                cm = confusion_matrix(model_data['label'], model_data['pred'], labels=[0,1])\n",
        "\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                           xticklabels=['Not Para','Para'],\n",
        "                           yticklabels=['Not Para','Para'],\n",
        "                           cbar=False)\n",
        "                axes[idx].set_title(f'{model_name}', fontsize=11, fontweight='bold')\n",
        "                axes[idx].set_ylabel('True' if idx == 0 else '', fontsize=10)\n",
        "                axes[idx].set_xlabel('Predicted', fontsize=10)\n",
        "\n",
        "            plt.suptitle('Confusion Matrices by LLM', fontsize=14, fontweight='bold', y=1.02)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            cm_plot_path = os.path.join(OUT, 'model_confusion_matrices.png')\n",
        "            plt.savefig(cm_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confusion matrices plot to {cm_plot_path}\")\n",
        "\n",
        "            # Create error analysis: false positives and false negatives by model\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "            error_data = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                fp = ((model_data['label'] == 0) & (model_data['pred'] == 1)).sum()\n",
        "                fn = ((model_data['label'] == 1) & (model_data['pred'] == 0)).sum()\n",
        "                tp = ((model_data['label'] == 1) & (model_data['pred'] == 1)).sum()\n",
        "                tn = ((model_data['label'] == 0) & (model_data['pred'] == 0)).sum()\n",
        "                error_data.append({\n",
        "                    'Model': model_name,\n",
        "                    'False Positives': fp,\n",
        "                    'False Negatives': fn,\n",
        "                    'True Positives': tp,\n",
        "                    'True Negatives': tn\n",
        "                })\n",
        "\n",
        "            error_df = pd.DataFrame(error_data)\n",
        "\n",
        "            # Plot false positives and false negatives\n",
        "            x = np.arange(len(error_df))\n",
        "            width = 0.35\n",
        "\n",
        "            ax1.bar(x - width/2, error_df['False Positives'], width, label='False Positives', color='salmon', alpha=0.8)\n",
        "            ax1.bar(x + width/2, error_df['False Negatives'], width, label='False Negatives', color='lightcoral', alpha=0.8)\n",
        "            ax1.set_ylabel('Count', fontsize=11)\n",
        "            ax1.set_xlabel('Model', fontsize=11)\n",
        "            ax1.set_title('Error Analysis: False Positives vs False Negatives', fontsize=12, fontweight='bold')\n",
        "            ax1.set_xticks(x)\n",
        "            ax1.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax1.legend()\n",
        "            ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            # Plot true positives and true negatives\n",
        "            ax2.bar(x - width/2, error_df['True Positives'], width, label='True Positives', color='mediumseagreen', alpha=0.8)\n",
        "            ax2.bar(x + width/2, error_df['True Negatives'], width, label='True Negatives', color='lightgreen', alpha=0.8)\n",
        "            ax2.set_ylabel('Count', fontsize=11)\n",
        "            ax2.set_xlabel('Model', fontsize=11)\n",
        "            ax2.set_title('Correct Predictions: True Positives vs True Negatives', fontsize=12, fontweight='bold')\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax2.legend()\n",
        "            ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            error_plot_path = os.path.join(OUT, 'model_error_analysis.png')\n",
        "            plt.savefig(error_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved error analysis plot to {error_plot_path}\")\n",
        "\n",
        "            # Distribution of confidence scores by model\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                ax.hist(model_data['prob_paraphrase'], bins=30, alpha=0.5, label=model_name, edgecolor='black')\n",
        "\n",
        "            ax.set_xlabel('Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Frequency', fontsize=12)\n",
        "            ax.set_title('Distribution of Paraphrase Detection Confidence Scores by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            ax.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            dist_plot_path = os.path.join(OUT, 'confidence_distribution.png')\n",
        "            plt.savefig(dist_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence distribution plot to {dist_plot_path}\")\n",
        "\n",
        "    # Save detailed per-sample results\n",
        "    display_df.to_csv(os.path.join(OUT, \"custom_results_detailed.csv\"), index=False)\n",
        "    print(f\"\\nSaved detailed results to {os.path.join(OUT, 'custom_results_detailed.csv')}\")\n",
        "    print(f\"Total samples evaluated: {len(display_df)}\")\n",
        "else:\n",
        "    print(\"\\nNo custom CSV results to display.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"All results saved to: {OUT}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  - summary.json, summary.csv: Overall metrics across datasets\")\n",
        "print(\"  - roc_comparison.png: ROC curves for DIPPER and HC3\")\n",
        "print(\"  - metrics_comparison.png: Bar chart comparing all metrics\")\n",
        "print(\"  - per_model_metrics.csv: Performance table by LLM\")\n",
        "print(\"  - per_model_performance.png: Bar chart of metrics by LLM\")\n",
        "print(\"  - model_confidence_scores.png: Average confidence by LLM\")\n",
        "print(\"  - model_confusion_matrices.png: Confusion matrices grid\")\n",
        "print(\"  - model_error_analysis.png: False positive/negative analysis\")\n",
        "print(\"  - confidence_distribution.png: Probability distributions\")\n",
        "print(\"  - custom_results_detailed.csv: Per-sample predictions\")\n",
        "print(\"=\"*80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-D__j3GqSNs7",
        "outputId": "a65c92b9-8f8a-456c-f85c-f475ec3999a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model/tokenizer: Intel/bert-base-uncased-mrpc ...\n",
            "[load_dipper_val] Searching for DIPPER valid/dev files under: /content/dipper_data\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx.tsv -> 1483\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx.tsv -> 1479\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx.tsv -> 1478\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx.tsv -> 1489\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx.tsv -> 1487\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx.tsv -> 1471\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx.tsv -> 1469\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx.tsv -> 1482\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx.tsv -> 1415\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx.tsv -> 1438\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx.tsv -> 1473\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/ctx_all.tsv\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx.tsv -> 1433\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx.tsv -> 1462\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "[gather_dipper_pos_val] Total valid-like files found: 176\n",
            "[load_dipper_val] Loaded DIPPER val: 8000 samples (label dist: {1: 5327, 0: 2673})\n",
            "Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4189474270.py:174: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n",
            "/tmp/ipython-input-4189474270.py:174: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  HC3 train: no_ctx=60205 ctx=60205\n",
            "Built HC3-eval: 8000 samples\n",
            "Loaded custom CSV: 90 (pos/neg: {1: 60, 0: 30})\n",
            "\n",
            "Evaluating DIPPER_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4189474270.py:299: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/bert_mrpc/dipper_val_confusion_matrix.png\n",
            "Saved /content/output/bert_mrpc/dipper_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.39      1.00      0.56      2673\n",
            "    Paraphrase       0.99      0.23      0.37      5327\n",
            "\n",
            "      accuracy                           0.49      8000\n",
            "     macro avg       0.69      0.61      0.47      8000\n",
            "  weighted avg       0.79      0.49      0.44      8000\n",
            "\n",
            "\n",
            "Evaluating HC3_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4189474270.py:299: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/bert_mrpc/hc3_val_confusion_matrix.png\n",
            "Saved /content/output/bert_mrpc/hc3_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.34      1.00      0.51      2664\n",
            "    Paraphrase       1.00      0.04      0.08      5336\n",
            "\n",
            "      accuracy                           0.36      8000\n",
            "     macro avg       0.67      0.52      0.30      8000\n",
            "  weighted avg       0.78      0.36      0.22      8000\n",
            "\n",
            "Saved summary.json to /content/output/bert_mrpc\n",
            "\n",
            "Evaluating CUSTOM_CSV (90 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4189474270.py:299: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/bert_mrpc/custom_csv_confusion_matrix.png\n",
            "Saved /content/output/bert_mrpc/custom_csv_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.82      0.93      0.88        30\n",
            "    Paraphrase       0.96      0.90      0.93        60\n",
            "\n",
            "      accuracy                           0.91        90\n",
            "     macro avg       0.89      0.92      0.90        90\n",
            "  weighted avg       0.92      0.91      0.91        90\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            sentence1  \\\n",
              "0   The possibility of approximating a continuous ...   \n",
              "1   State-of-the-art object detection networks dep...   \n",
              "2   I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "3   Our evolutionary history suggests that there w...   \n",
              "4   The possibility of approximating a continuous ...   \n",
              "..                                                ...   \n",
              "85  The possibility of approximating a continuous ...   \n",
              "86  In fact, science and technology are clearly di...   \n",
              "87  I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "88  Our evolutionary history suggests that there w...   \n",
              "89  We study a novel machine learning (ML) problem...   \n",
              "\n",
              "                                            sentence2  label  pred  \\\n",
              "0   Several studies have examined the ability of a...      1     0   \n",
              "1   Leading object detection networks rely on regi...      1     1   \n",
              "2   I had resolved not to write a \"Top Whatever\" b...      1     0   \n",
              "3   Indeed, science and technology are distinctly ...      0     0   \n",
              "4   Numerous research papers have investigated the...      1     0   \n",
              "..                                                ...    ...   ...   \n",
              "85  A feedforward neural network with one hidden l...      1     0   \n",
              "86  In a recent opinion piece in The Conversation,...      0     0   \n",
              "87  We investigate a new machine learning problem ...      0     0   \n",
              "88  Our evolutionary history indicates that there ...      1     1   \n",
              "89  We investigate a new machine learning problem ...      1     0   \n",
              "\n",
              "    prob_paraphrase  \n",
              "0          0.419090  \n",
              "1          0.909879  \n",
              "2          0.007163  \n",
              "3          0.013192  \n",
              "4          0.295652  \n",
              "..              ...  \n",
              "85         0.432861  \n",
              "86         0.006711  \n",
              "87         0.004467  \n",
              "88         0.897419  \n",
              "89         0.458022  \n",
              "\n",
              "[90 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8bada8e8-ab6b-4c93-98d3-b81e322678eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_paraphrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Several studies have examined the ability of a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.419090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>State-of-the-art object detection networks dep...</td>\n",
              "      <td>Leading object detection networks rely on regi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.909879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>I had resolved not to write a \"Top Whatever\" b...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Indeed, science and technology are distinctly ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.013192</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Numerous research papers have investigated the...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.295652</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>A feedforward neural network with one hidden l...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.432861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>In fact, science and technology are clearly di...</td>\n",
              "      <td>In a recent opinion piece in The Conversation,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.006711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.004467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Our evolutionary history indicates that there ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.897419</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>We study a novel machine learning (ML) problem...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.458022</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8bada8e8-ab6b-4c93-98d3-b81e322678eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8bada8e8-ab6b-4c93-98d3-b81e322678eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8bada8e8-ab6b-4c93-98d3-b81e322678eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-19ceec45-4bc0-4338-a1e9-f8213960e6e2\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19ceec45-4bc0-4338-a1e9-f8213960e6e2')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-19ceec45-4bc0-4338-a1e9-f8213960e6e2 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"No custom CSV results to display\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Andrew Ng hands me a tiny device that wraps around my ear and connects to a smartphone via a small cable. It looks like a throwback---a smartphone earpiece without a Bluetooth connection. But it's really a glimpse of the future. In a way, this tiny device allows the blind to see.\",\n          \"The possibility of approximating a continuous function on a compact subset of the real line by a feedforward single hidden layer neural network with a sigmoidal activation function has been studied in many papers. \",\n          \"We study a novel machine learning (ML) problem setting of sequentially allocating small subsets of training data amongst a large set of classifiers. The goal is to select a classifier that will give near-optimal accuracy when trained on all data, while also minimizing the cost of misallocated samples.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Several studies have examined the ability of a single hidden layer feedforward neural network with a sigmoidal activation function to approximate a continuous function on a compact subset of the real line.\",\n          \"Professor Lord Krebs stated in a recent opinion article in The Conversation that \\\"accurate reporting of science matters\\\" and that scientists have a professional obligation to \\\"challenge poor media reporting on climate change\\\".\",\n          \"I promise I had no intention of writing a \\\"Top Whatevers of 2015\\\" blog post this year, but then Slate's Benevolent Overlords requested I write one, and what option did I have? They're benevolent, yet they remain overlords. Additionally, I'm fond of them.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_paraphrase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3296933494796381,\n        \"min\": 0.004013364668935537,\n        \"max\": 0.988523006439209,\n        \"num_unique_values\": 89,\n        \"samples\": [\n          0.013919811695814133,\n          0.008116442710161209\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved custom_results.csv to /content/output/bert_mrpc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intel/deberta-v3-base-mrpc"
      ],
      "metadata": {
        "id": "rzl64WyocVFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "# Delete model, tokenizer, and any large tensors\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "I7ScqrHYw4ad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"Intel/deberta-v3-base-mrpc\"\n",
        "OUTPUT_ROOT = Path(\"./output/deberta_v3_mrpc\").resolve()\n",
        "\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_MIXED_PRECISION = True\n",
        "\n",
        "# ----- cleaning/parsing helpers (unchanged except robust column handling) -----\n",
        "def clean_sentence(sent: str) -> str:\n",
        "    s = str(sent)\n",
        "    s = re.sub(r\"lexical\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r\"order\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = s.replace(\"<sent>\", \" \")\n",
        "    # If the cell contains quoted pieces, keep the quoted content (like original code)\n",
        "    matches = re.findall(r'\"([^\"]+)\"', s)\n",
        "    if matches:\n",
        "        s = \" \".join(matches)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.replace(\", ,\", \",\").strip()\n",
        "    return s\n",
        "\n",
        "def parse_dipper_tsv(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    # Expect at least two columns; some tsvs may have extra columns (we only need first two)\n",
        "    if df is None or df.shape[1] < 2:\n",
        "        return pd.DataFrame(columns=[\"sentence1\", \"sentence2\", \"label\"])\n",
        "    # force using first two columns no matter the header\n",
        "    c1, c2 = df.columns[0], df.columns[1]\n",
        "    s1 = df[c1].astype(str).map(clean_sentence)\n",
        "    s2 = df[c2].astype(str).map(clean_sentence)\n",
        "    out = pd.DataFrame({\"sentence1\": s1, \"sentence2\": s2})\n",
        "    # filter too-short entries (same thresholds as you used)\n",
        "    out = out[(out[\"sentence1\"].str.len() > 8) & (out[\"sentence2\"].str.len() > 8)].copy()\n",
        "    out[\"label\"] = 1\n",
        "    out.dropna(inplace=True)\n",
        "    out.reset_index(drop=True, inplace=True)\n",
        "    return out\n",
        "\n",
        "def _read_tsv(path: str, nrows: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Read a TSV file defensively.\n",
        "    Return DataFrame with whatever columns read (header=None fallback).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # try without header first (most DIPPER tsvs are headerless)\n",
        "        return pd.read_csv(path, sep=\"\\t\", nrows=nrows, header=None, engine=\"python\", quoting=3)\n",
        "    except Exception:\n",
        "        try:\n",
        "            # fallback: let pandas infer header\n",
        "            return pd.read_csv(path, sep=\"\\t\", nrows=nrows, engine=\"python\")\n",
        "        except Exception:\n",
        "            # last resort: return None\n",
        "            return None\n",
        "\n",
        "# ----- New recursive gather function that matches your tree -----\n",
        "def gather_dipper_pos_val(root: str, nrows_val: Optional[int] = 1500) -> List[pd.DataFrame]:\n",
        "    \"\"\"\n",
        "    Recursively search `root` for any sents_* directories and collect valid/dev-like TSVs.\n",
        "    Returns a list of positive-only DataFrames (label=1).\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    if not os.path.exists(root):\n",
        "        print(f\"[gather_dipper_pos_val] DIPPER root not found: {root}\")\n",
        "        return out\n",
        "\n",
        "    # patterns to accept: valid/dev variants, ctx_all/no_ctx_all variants, and 'valid..._all' etc.\n",
        "    # We'll accept any filename that contains 'valid' or 'dev' or exactly 'ctx_all' / 'no_ctx_all'\n",
        "    # but exclude 'train' files.\n",
        "    def is_valid_file(fname: str) -> bool:\n",
        "        lower = fname.lower()\n",
        "        if \"train\" in lower:\n",
        "            return False\n",
        "        if \"valid\" in lower or \"dev\" in lower or \"ctx_all\" in lower or \"no_ctx_all\" in lower:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    found_files = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        base = os.path.basename(dirpath)\n",
        "        # focus on directories named 'sents_*' (covers the structure you posted)\n",
        "        if not base.startswith(\"sents_\"):\n",
        "            continue\n",
        "        for fname in filenames:\n",
        "            if not fname.lower().endswith(\".tsv\"):\n",
        "                continue\n",
        "            if is_valid_file(fname):\n",
        "                fpath = os.path.join(dirpath, fname)\n",
        "                found_files.append(fpath)\n",
        "                try:\n",
        "                    df_raw = _read_tsv(fpath, nrows=nrows_val)\n",
        "                    df = parse_dipper_tsv(df_raw) if df_raw is not None else None\n",
        "                    if df is not None and len(df) > 0:\n",
        "                        out.append(df)\n",
        "                        print(f\"  ✓ found DIPPER valid-like: {os.path.relpath(fpath, start=root)} -> {len(df)}\")\n",
        "                    else:\n",
        "                        print(f\"  ○ read but no usable rows: {os.path.relpath(fpath, start=root)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  ! failed reading {fpath}: {e}\")\n",
        "\n",
        "    # Also check for some out_domain ctx_all/no_ctx_all files sitting under something like out_domain/*/sents_*\n",
        "    # (the above walk will already hit them because they are under sents_*; this comment is just informative)\n",
        "    if not found_files:\n",
        "        print(f\"[gather_dipper_pos_val] No valid/dev files found under {root}.\")\n",
        "    else:\n",
        "        print(f\"[gather_dipper_pos_val] Total valid-like files found: {len(found_files)}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "# ----- Add negatives (unchanged) -----\n",
        "def add_negatives(df: pd.DataFrame, ratio=1.0, seed=42) -> pd.DataFrame:\n",
        "    pos = df.copy().reset_index(drop=True)\n",
        "    n = len(pos)\n",
        "    if n < 4:\n",
        "        return pos\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(n)\n",
        "    half = n // 2\n",
        "    neg = pd.DataFrame({\n",
        "        \"sentence1\": pos.loc[idx[:half], \"sentence1\"].values,\n",
        "        \"sentence2\": pos.loc[idx[-half:], \"sentence2\"].values,\n",
        "        \"label\": 0\n",
        "    })\n",
        "    if len(neg) > int(len(pos) * ratio):\n",
        "        neg = neg.sample(int(len(pos) * ratio), random_state=seed)\n",
        "    pos[\"label\"] = 1\n",
        "    out = pd.concat([pos, neg], ignore_index=True).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def load_dipper_val(dipper_root: str = \"/content/dipper_data\", val_size_limit: int = 8000) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Build a DIPPER validation DF by aggregating all positive valid-like files found under dipper_root,\n",
        "    then adding negatives and sampling a validation set.\n",
        "    \"\"\"\n",
        "    print(f\"[load_dipper_val] Searching for DIPPER valid/dev files under: {dipper_root}\")\n",
        "    pos_list = gather_dipper_pos_val(dipper_root)\n",
        "    if not pos_list:\n",
        "        raise RuntimeError(\"No DIPPER valid-like files found under dipper_root. Check path and filename conventions.\")\n",
        "    pos_all = pd.concat(pos_list, ignore_index=True)\n",
        "    # deduplicate near-identical pairs (optional): uncomment if needed\n",
        "    # pos_all = pos_all.drop_duplicates(subset=[\"sentence1\",\"sentence2\"]).reset_index(drop=True)\n",
        "    full = add_negatives(pos_all, ratio=1.0)\n",
        "    val_size = min(val_size_limit, max(2000, int(0.1 * len(full))))\n",
        "    val_df = full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[load_dipper_val] Loaded DIPPER val: {len(val_df)} samples (label dist: {val_df['label'].value_counts().to_dict()})\")\n",
        "    return val_df\n",
        "\n",
        "# HC3 helpers (adapted from your code)\n",
        "def to_list_safely(x):\n",
        "    if x is None: return []\n",
        "    try:\n",
        "        if pd.isna(x): return []\n",
        "    except Exception:\n",
        "        pass\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return [str(e).strip() for e in x if str(e).strip()]\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return [str(e).strip() for e in x.tolist() if str(e).strip()]\n",
        "    s = str(x).strip()\n",
        "    return [s] if s else []\n",
        "\n",
        "def make_pairs_from_hc3_split(ds_split, add_context: bool, cartesian: bool = True):\n",
        "    df = ds_split.to_pandas()\n",
        "    rows = []\n",
        "    human_col = \"human_answers\" if \"human_answers\" in df.columns else \"human_answers\"\n",
        "    ai_col = \"chatgpt_answers\" if \"chatgpt_answers\" in df.columns else \"chatgpt_answers\"\n",
        "    q_col = \"question\" if \"question\" in df.columns else None\n",
        "    for _, r in df.iterrows():\n",
        "        q = \"\"\n",
        "        if q_col is not None and q_col in r:\n",
        "            q = str(r[q_col]).strip()\n",
        "        human_list = to_list_safely(r.get(human_col))\n",
        "        ai_list = to_list_safely(r.get(ai_col))\n",
        "        if not human_list or not ai_list:\n",
        "            continue\n",
        "        prefix = \"lexical = NA, order = NA\"\n",
        "        if cartesian:\n",
        "            for h in human_list:\n",
        "                for a in ai_list:\n",
        "                    if add_context and q:\n",
        "                        col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                    else:\n",
        "                        col0 = f\"{prefix} {h}\"\n",
        "                    rows.append((col0, a))\n",
        "        else:\n",
        "            k = min(len(human_list), len(ai_list))\n",
        "            for i in range(k):\n",
        "                h = human_list[i]; a = ai_list[i]\n",
        "                if add_context and q:\n",
        "                    col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                else:\n",
        "                    col0 = f\"{prefix} {h}\"\n",
        "                rows.append((col0, a))\n",
        "    return pd.DataFrame(rows, columns=[0, 1])\n",
        "\n",
        "def build_hc3_tsvs(cartesian=True):\n",
        "    print(\"Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\")\n",
        "    hc3 = load_dataset(\"Hello-SimpleAI/HC3\", \"all\")\n",
        "    all_splits = {}\n",
        "    for split in hc3.keys():\n",
        "        df_no_ctx = make_pairs_from_hc3_split(hc3[split], add_context=False, cartesian=cartesian)\n",
        "        df_no_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_no_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_no_ctx\"] = df_no_ctx\n",
        "        df_ctx = make_pairs_from_hc3_split(hc3[split], add_context=True, cartesian=cartesian)\n",
        "        df_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_ctx\"] = df_ctx\n",
        "        print(f\"  HC3 {split}: no_ctx={len(df_no_ctx)} ctx={len(df_ctx)}\")\n",
        "    # We'll return concatenation of available splits for evaluation\n",
        "    if len(all_splits) == 0:\n",
        "        raise RuntimeError(\"HC3 had no splits.\")\n",
        "    combined = pd.concat(list(all_splits.values()), ignore_index=True)\n",
        "    # Add negatives by shuffling similar to DIPPER\n",
        "    combined_full = add_negatives(combined, ratio=1.0)\n",
        "    # sample validation-size portion (keep reasonable)\n",
        "    val_size = min(8000, max(2000, int(0.1 * len(combined_full))))\n",
        "    val_df = combined_full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"Built HC3-eval: {len(val_df)} samples\")\n",
        "    return val_df\n",
        "\n",
        "# ----- Torch Dataset -----\n",
        "class PairEvalDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_length=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.loc[idx]\n",
        "        a = str(r[\"sentence1\"])\n",
        "        b = str(r[\"sentence2\"])\n",
        "        toks = self.tok(a, b, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in toks.items()}\n",
        "        item[\"label\"] = torch.tensor(int(r[\"label\"]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# ----- Evaluation functions -----\n",
        "def save_confusion_matrix(cm: np.ndarray, dataset_name: str, output_dir: str, normalize: bool = False):\n",
        "    fmt = 'd'\n",
        "    cbar_label = 'Count'\n",
        "    title = f\"{dataset_name} - Confusion Matrix\"\n",
        "    cm_plot = cm\n",
        "    if normalize:\n",
        "        cm_plot = cm.astype(float)\n",
        "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
        "        cm_plot = np.divide(cm_plot, row_sums, where=row_sums != 0)\n",
        "        fmt = '.2f'\n",
        "        cbar_label = 'Proportion'\n",
        "        title = f\"{dataset_name} - Normalized Confusion Matrix\"\n",
        "    plt.figure(figsize=(5.5,4.5))\n",
        "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap='Blues',\n",
        "                xticklabels=['Not Paraphrase','Paraphrase'], yticklabels=['Not Paraphrase','Paraphrase'],\n",
        "                cbar_kws={'label': cbar_label})\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    suffix = '_normalized' if normalize else ''\n",
        "    fname = os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_confusion_matrix{suffix}.png\")\n",
        "    plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {fname}\")\n",
        "\n",
        "def evaluate_and_save(model, tokenizer, df: pd.DataFrame, dataset_name: str, output_dir: str, batch_size: int = 64, device: torch.device = DEVICE):\n",
        "    if df is None or len(df) == 0:\n",
        "        print(f\"Skipping {dataset_name} - no data\")\n",
        "        return None, (None, None)\n",
        "    print(f\"\\nEvaluating {dataset_name} ({len(df)} samples)\")\n",
        "    ds = PairEvalDataset(df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "    model.to(device); model.eval()\n",
        "    all_preds = []; all_labels = []; all_probs = []\n",
        "    use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "    amp_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "    with torch.no_grad():\n",
        "        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n",
        "            for batch in loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                token_type_ids = batch.get('token_type_ids', None)\n",
        "                if token_type_ids is not None:\n",
        "                    token_type_ids = token_type_ids.to(device)\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "                else:\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = out.logits\n",
        "                probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
        "                preds = (probs > 0.5).astype(int)\n",
        "                all_preds.extend(preds.tolist())\n",
        "                all_labels.extend(batch['label'].cpu().numpy().tolist())\n",
        "                all_probs.extend(probs.tolist())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds) if len(set(all_labels))>1 else 0.0\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=[0,1])\n",
        "    auc = None; fpr = None; tpr = None; tpr_1pct = None\n",
        "    try:\n",
        "        auc = float(roc_auc_score(all_labels, all_probs))\n",
        "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "        if len(fpr)>1:\n",
        "            tpr_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "    except Exception:\n",
        "        pass\n",
        "    metrics = {\n",
        "        'dataset': dataset_name,\n",
        "        'accuracy': float(acc),\n",
        "        'precision': float(p),\n",
        "        'recall': float(r),\n",
        "        'f1': float(f1),\n",
        "        'mcc': float(mcc),\n",
        "        'auc': auc,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'samples': len(df),\n",
        "        'tpr_at_1pct_fpr': tpr_1pct,\n",
        "        'fpr': fpr.tolist() if fpr is not None else None,\n",
        "        'tpr': tpr.tolist() if tpr is not None else None\n",
        "    }\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=False)\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=True)\n",
        "    with open(os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_metrics.json\"), \"w\") as fh:\n",
        "        json.dump(metrics, fh, indent=2)\n",
        "    print(classification_report(all_labels, all_preds, target_names=['Not Paraphrase','Paraphrase']))\n",
        "    return metrics, (all_labels, all_probs)\n",
        "\n",
        "# ----- Load model & tokenizer -----\n",
        "print(f\"Loading model/tokenizer: {MODEL_NAME} ...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# ----- Prepare datasets -----\n",
        "try:\n",
        "    dipper_val = load_dipper_val(\"/content/dipper_data\")\n",
        "except Exception as e:\n",
        "    print(\"Warning: DIPPER load failed:\", e)\n",
        "    dipper_val = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "try:\n",
        "    hc3_df = build_hc3_tsvs(cartesian=True)\n",
        "except Exception as e:\n",
        "    print(\"Warning: HC3 load failed:\", e)\n",
        "    hc3_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "# Custom CSV\n",
        "CUSTOM_CSV_PATH = \"/content/custom_paraphrases.csv\"\n",
        "custom_df = None\n",
        "if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "    cdf = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "    if {\"original_sentence\",\"paraphrased_sentence\"}.issubset(set(cdf.columns)):\n",
        "        custom_df = pd.DataFrame({\n",
        "            \"sentence1\": cdf[\"original_sentence\"].astype(str),\n",
        "            \"sentence2\": cdf[\"paraphrased_sentence\"].astype(str),\n",
        "            \"label\": 1\n",
        "        })\n",
        "        custom_eval_df = add_negatives(custom_df, ratio=1.0)\n",
        "        print(f\"Loaded custom CSV: {len(custom_eval_df)} (pos/neg: {custom_eval_df['label'].value_counts().to_dict()})\")\n",
        "    else:\n",
        "        print(\"Custom CSV missing required columns. Skipping custom.\")\n",
        "        custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "else:\n",
        "    print(f\"Custom CSV not found at {CUSTOM_CSV_PATH}. Skipping custom.\")\n",
        "    custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "OUT = OUTPUT_ROOT\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ----- Evaluate DIPPER and HC3 -----\n",
        "all_metrics = []\n",
        "roc_entries = []\n",
        "for df, name in [(dipper_val, \"DIPPER_VAL\"), (hc3_df, \"HC3_VAL\")]:\n",
        "    if df is None or len(df)==0:\n",
        "        print(f\"Skipping {name} - no data\")\n",
        "        continue\n",
        "    metrics, (labels, probs) = evaluate_and_save(model, tokenizer, df, name, str(OUT), batch_size=BATCH_SIZE)\n",
        "    if metrics:\n",
        "        all_metrics.append(metrics)\n",
        "        if metrics.get('auc') is not None and metrics.get('fpr') is not None:\n",
        "            roc_entries.append({\n",
        "                'dataset': name,\n",
        "                'fpr': np.array(metrics['fpr']),\n",
        "                'tpr': np.array(metrics['tpr']),\n",
        "                'auc': metrics['auc'],\n",
        "                'accuracy': metrics['accuracy']\n",
        "            })\n",
        "\n",
        "with open(os.path.join(OUT, \"summary.json\"), \"w\") as fh:\n",
        "    json.dump(all_metrics, fh, indent=2)\n",
        "print(f\"Saved summary.json to {OUT}\")\n",
        "\n",
        "# ----- Plot ROC curves comparison -----\n",
        "if len(roc_entries) > 0:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    cmap = plt.get_cmap('tab10')\n",
        "    lines = []\n",
        "    labels_list = []\n",
        "    for i, entry in enumerate(roc_entries):\n",
        "        color = cmap(i % 10)\n",
        "        fpr = entry['fpr']\n",
        "        tpr = entry['tpr']\n",
        "        auc_val = entry['auc']\n",
        "        acc_val = entry['accuracy']\n",
        "\n",
        "        if len(fpr) == 0 or len(tpr) == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tpr_at_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "        except Exception:\n",
        "            tpr_at_1pct = 0.0\n",
        "        plt.plot(fpr, tpr, label=None, color=color, linewidth=2)\n",
        "        legend_label = f\"{entry['dataset']} (AUC={auc_val:.3f}, TPR@1%FPR={tpr_at_1pct:.3f}, Acc={acc_val:.3f})\"\n",
        "        lines.append(plt.Line2D([0],[0], color=color, lw=2))\n",
        "        labels_list.append(legend_label)\n",
        "\n",
        "    plt.plot([0,1],[0,1], linestyle='--', color='gray', linewidth=1.5, label='Random')\n",
        "    plt.xlim([0.0,1.0])\n",
        "    plt.ylim([0.0,1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(lines + [plt.Line2D([0],[0], color='gray', lw=1.5, linestyle='--')],\n",
        "               labels_list + ['Random'], loc='lower right', fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "    roc_path = os.path.join(OUT, 'roc_comparison.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {roc_path}\")\n",
        "else:\n",
        "    print('No ROC data available for plotting.')\n",
        "\n",
        "# ----- Plot performance metrics comparison -----\n",
        "if len(all_metrics) > 1:\n",
        "    comp_df = pd.DataFrame(all_metrics)\n",
        "    comp_df_sorted = comp_df.set_index('dataset')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    comp_df_sorted[['accuracy','precision','recall','f1','mcc','auc','tpr_at_1pct_fpr']].plot(\n",
        "        kind='bar', ax=ax, width=0.8)\n",
        "    plt.title('Performance Metrics Comparison Across Datasets', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Score', fontsize=12)\n",
        "    plt.xlabel('Dataset', fontsize=12)\n",
        "    plt.ylim(0,1.05)\n",
        "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    comp_path = os.path.join(OUT, 'metrics_comparison.png')\n",
        "    plt.savefig(comp_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {comp_path}\")\n",
        "\n",
        "# ----- Print and save summary table -----\n",
        "summary_df = pd.DataFrame(all_metrics)\n",
        "if not summary_df.empty:\n",
        "    display_cols = ['dataset','accuracy','precision','recall','f1','mcc',\n",
        "                'auc','tpr_at_1pct_fpr','samples']\n",
        "    print('\\n' + '='*80)\n",
        "    print('SUMMARY TABLE')\n",
        "    print('='*80)\n",
        "    print(summary_df[display_cols].round(4).to_string(index=False))\n",
        "    print('='*80)\n",
        "    summary_df.to_csv(os.path.join(OUT, 'summary.csv'), index=False)\n",
        "    print(f\"\\nSaved summary table to {os.path.join(OUT, 'summary.csv')}\")\n",
        "\n",
        "# ----- Evaluate custom CSV and create per-model analysis -----\n",
        "if custom_eval_df is not None and len(custom_eval_df)>0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CUSTOM CSV EVALUATION - PER-MODEL ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    metrics_c, (labels_c, probs_c) = evaluate_and_save(model, tokenizer, custom_eval_df, \"CUSTOM_CSV\", str(OUT), batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Get predictions for all samples\n",
        "    ds_custom = PairEvalDataset(custom_eval_df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds_custom, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    preds_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = F.softmax(out.logits, dim=-1)[:,1].cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            for i in range(len(preds)):\n",
        "                preds_list.append({'pred': int(preds[i]), 'prob_paraphrase': float(probs[i])})\n",
        "\n",
        "    # Combine with original data\n",
        "    report_df = custom_eval_df.copy().reset_index(drop=True)\n",
        "    preds_df = pd.DataFrame(preds_list)\n",
        "    display_df = pd.concat([report_df, preds_df], axis=1)\n",
        "\n",
        "    # Load original CSV to get model names\n",
        "    if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "        orig_csv = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "        if 'model_name' in orig_csv.columns:\n",
        "            display_df['model_name'] = orig_csv['model_name'].values[:len(display_df)]\n",
        "\n",
        "            # Calculate per-model metrics\n",
        "            model_metrics = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                labels_m = model_data['label'].values\n",
        "                preds_m = model_data['pred'].values\n",
        "\n",
        "                acc = accuracy_score(labels_m, preds_m)\n",
        "                p, r, f1, _ = precision_recall_fscore_support(labels_m, preds_m, average='binary', zero_division=0)\n",
        "\n",
        "                model_metrics.append({\n",
        "                    'Model': model_name,\n",
        "                    'Precision (%)': p * 100,\n",
        "                    'Recall (%)': r * 100,\n",
        "                    'F1-Score (%)': f1 * 100,\n",
        "                    'Accuracy (%)': acc * 100,\n",
        "                    'Samples': len(model_data)\n",
        "                })\n",
        "\n",
        "            model_perf_df = pd.DataFrame(model_metrics)\n",
        "\n",
        "            # Display and save per-model table\n",
        "            print(\"\\nPer-Model Performance:\")\n",
        "            print(model_perf_df.round(2).to_string(index=False))\n",
        "            model_perf_df.to_csv(os.path.join(OUT, \"per_model_metrics.csv\"), index=False)\n",
        "            print(f\"\\nSaved per-model metrics to {os.path.join(OUT, 'per_model_metrics.csv')}\")\n",
        "\n",
        "            # Plot per-model performance\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            x = np.arange(len(model_perf_df))\n",
        "            width = 0.2\n",
        "\n",
        "            ax.bar(x - 1.5*width, model_perf_df['Precision (%)'], width, label='Precision', alpha=0.8)\n",
        "            ax.bar(x - 0.5*width, model_perf_df['Recall (%)'], width, label='Recall', alpha=0.8)\n",
        "            ax.bar(x + 0.5*width, model_perf_df['F1-Score (%)'], width, label='F1-Score', alpha=0.8)\n",
        "            ax.bar(x + 1.5*width, model_perf_df['Accuracy (%)'], width, label='Accuracy', alpha=0.8)\n",
        "\n",
        "            ax.set_ylabel('Score (%)', fontsize=12)\n",
        "            ax.set_xlabel('Model', fontsize=12)\n",
        "            ax.set_title('Paraphrase Detection Performance by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(model_perf_df['Model'], rotation=45, ha='right')\n",
        "            ax.legend()\n",
        "            ax.set_ylim(0, 105)\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            model_plot_path = os.path.join(OUT, 'per_model_performance.png')\n",
        "            plt.savefig(model_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved per-model plot to {model_plot_path}\")\n",
        "\n",
        "            # Plot average probability scores by model\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            model_probs = display_df.groupby('model_name')['prob_paraphrase'].agg(['mean', 'std'])\n",
        "            model_probs = model_probs.sort_values('mean', ascending=False)\n",
        "\n",
        "            ax.barh(model_probs.index, model_probs['mean'], xerr=model_probs['std'],\n",
        "                   capsize=5, alpha=0.7, color='steelblue')\n",
        "            ax.set_xlabel('Average Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Model', fontsize=12)\n",
        "            ax.set_title('Average Paraphrase Detection Confidence by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.grid(axis='x', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            prob_plot_path = os.path.join(OUT, 'model_confidence_scores.png')\n",
        "            plt.savefig(prob_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence scores plot to {prob_plot_path}\")\n",
        "\n",
        "            # Heatmap of per-model confusion matrices\n",
        "            n_models = len(model_perf_df)\n",
        "            fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
        "            if n_models == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            for idx, model_name in enumerate(display_df['model_name'].unique()):\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                cm = confusion_matrix(model_data['label'], model_data['pred'], labels=[0,1])\n",
        "\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                           xticklabels=['Not Para','Para'],\n",
        "                           yticklabels=['Not Para','Para'],\n",
        "                           cbar=False)\n",
        "                axes[idx].set_title(f'{model_name}', fontsize=11, fontweight='bold')\n",
        "                axes[idx].set_ylabel('True' if idx == 0 else '', fontsize=10)\n",
        "                axes[idx].set_xlabel('Predicted', fontsize=10)\n",
        "\n",
        "            plt.suptitle('Confusion Matrices by LLM', fontsize=14, fontweight='bold', y=1.02)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            cm_plot_path = os.path.join(OUT, 'model_confusion_matrices.png')\n",
        "            plt.savefig(cm_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confusion matrices plot to {cm_plot_path}\")\n",
        "\n",
        "            # Create error analysis: false positives and false negatives by model\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "            error_data = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                fp = ((model_data['label'] == 0) & (model_data['pred'] == 1)).sum()\n",
        "                fn = ((model_data['label'] == 1) & (model_data['pred'] == 0)).sum()\n",
        "                tp = ((model_data['label'] == 1) & (model_data['pred'] == 1)).sum()\n",
        "                tn = ((model_data['label'] == 0) & (model_data['pred'] == 0)).sum()\n",
        "                error_data.append({\n",
        "                    'Model': model_name,\n",
        "                    'False Positives': fp,\n",
        "                    'False Negatives': fn,\n",
        "                    'True Positives': tp,\n",
        "                    'True Negatives': tn\n",
        "                })\n",
        "\n",
        "            error_df = pd.DataFrame(error_data)\n",
        "\n",
        "            # Plot false positives and false negatives\n",
        "            x = np.arange(len(error_df))\n",
        "            width = 0.35\n",
        "\n",
        "            ax1.bar(x - width/2, error_df['False Positives'], width, label='False Positives', color='salmon', alpha=0.8)\n",
        "            ax1.bar(x + width/2, error_df['False Negatives'], width, label='False Negatives', color='lightcoral', alpha=0.8)\n",
        "            ax1.set_ylabel('Count', fontsize=11)\n",
        "            ax1.set_xlabel('Model', fontsize=11)\n",
        "            ax1.set_title('Error Analysis: False Positives vs False Negatives', fontsize=12, fontweight='bold')\n",
        "            ax1.set_xticks(x)\n",
        "            ax1.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax1.legend()\n",
        "            ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            # Plot true positives and true negatives\n",
        "            ax2.bar(x - width/2, error_df['True Positives'], width, label='True Positives', color='mediumseagreen', alpha=0.8)\n",
        "            ax2.bar(x + width/2, error_df['True Negatives'], width, label='True Negatives', color='lightgreen', alpha=0.8)\n",
        "            ax2.set_ylabel('Count', fontsize=11)\n",
        "            ax2.set_xlabel('Model', fontsize=11)\n",
        "            ax2.set_title('Correct Predictions: True Positives vs True Negatives', fontsize=12, fontweight='bold')\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax2.legend()\n",
        "            ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            error_plot_path = os.path.join(OUT, 'model_error_analysis.png')\n",
        "            plt.savefig(error_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved error analysis plot to {error_plot_path}\")\n",
        "\n",
        "            # Distribution of confidence scores by model\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                ax.hist(model_data['prob_paraphrase'], bins=30, alpha=0.5, label=model_name, edgecolor='black')\n",
        "\n",
        "            ax.set_xlabel('Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Frequency', fontsize=12)\n",
        "            ax.set_title('Distribution of Paraphrase Detection Confidence Scores by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            ax.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            dist_plot_path = os.path.join(OUT, 'confidence_distribution.png')\n",
        "            plt.savefig(dist_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence distribution plot to {dist_plot_path}\")\n",
        "\n",
        "    # Save detailed per-sample results\n",
        "    display_df.to_csv(os.path.join(OUT, \"custom_results_detailed.csv\"), index=False)\n",
        "    print(f\"\\nSaved detailed results to {os.path.join(OUT, 'custom_results_detailed.csv')}\")\n",
        "    print(f\"Total samples evaluated: {len(display_df)}\")\n",
        "else:\n",
        "    print(\"\\nNo custom CSV results to display.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"All results saved to: {OUT}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  - summary.json, summary.csv: Overall metrics across datasets\")\n",
        "print(\"  - roc_comparison.png: ROC curves for DIPPER and HC3\")\n",
        "print(\"  - metrics_comparison.png: Bar chart comparing all metrics\")\n",
        "print(\"  - per_model_metrics.csv: Performance table by LLM\")\n",
        "print(\"  - per_model_performance.png: Bar chart of metrics by LLM\")\n",
        "print(\"  - model_confidence_scores.png: Average confidence by LLM\")\n",
        "print(\"  - model_confusion_matrices.png: Confusion matrices grid\")\n",
        "print(\"  - model_error_analysis.png: False positive/negative analysis\")\n",
        "print(\"  - confidence_distribution.png: Probability distributions\")\n",
        "print(\"  - custom_results_detailed.csv: Per-sample predictions\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c274ed5d638b41ecba477cb38fb75644",
            "acb7a719651241a783836094ce3ac74c",
            "11511ceb99fb43d88b301e136f45794b",
            "72c09a1f6de74135a85a0d2bb5713c5f",
            "068e6f6ddbc944c89c82cdd8710a9ff5",
            "cfa9ca437f7044bfb91fd8b6a8e198ee",
            "6c8be6372f8e4c98bd36835d80c02363",
            "db202ca452b84280954c98e0a5fb58d1",
            "8b77a7198ff9422db0c256296200a1bd",
            "deb42771c1644bf6816f240fa51dd336",
            "ac9d59af248d4a6ab697c0403299b1f6",
            "0d2be1d3c77f4f488230546661b0a11e",
            "b110c58931374501a4f7f25eae59a229",
            "f0cafb79856f40f1bd703124c1183166",
            "a9f9e37b0a9b494c82a0ba9d87fdf14b",
            "a2a8d4c9f9a848bca384a2e2bda3871d",
            "a18a55c7a3b64fc98d1e29605772cd53",
            "0e3fbee35d08455faa911a3bc8387d1c",
            "00b4dc6fa71c4978aa264dc5e790b893",
            "cc13d13bd0ae4b39be5b0b738374bbe9",
            "8024b01f73994747925809c3606c0936",
            "5ac2b04d6eda4709962a552cc42dae0d",
            "c21c379d22324010bb50e678bcf7ab4f",
            "51bd7d9f9edc410197893f5a608e67b0",
            "9bbc521dcb1b4598b8d1cb193604fa28",
            "6ece4b419aa6426ab8adc065d4c6e71f",
            "cc6cebea7fed4c13b560847446563a2e",
            "0250ceddd08e4dbcb22f33bd721aed39",
            "5fd798fe1d8844648b16250e0ad1c951",
            "45f49caca132485aaf9b9ae87dced40e",
            "6538caf41cb3490f9c3f133979302d4c",
            "1c2e58bd23824e91b2c1221bdaf7e46f",
            "0f0085df8341490bb8055de71a26e2d5",
            "d70d9cc5b04a43b282ac0650083587a9",
            "b96ce79c941b4539bd8f21894da805b1",
            "631f2c38f9da432195ec337e9a6384d4",
            "7823a81a1866442585525d72d2571ec8",
            "8107945444f941f08f3373f289b6f0cc",
            "e07dc49fd1ae4b7cbeeeb5880c062ce2",
            "2341fa106d824720b9a3bacbdac46e69",
            "c6ce0d6ea7c549029778e4d3a1ec2adb",
            "4c1cd8886bd14a81aa635d2f5310feb7",
            "2526145edff145479bc02999ee6a0410",
            "aa69bfbf1b764fb0b6ae5dba7b1360a2",
            "e1c72076a75f45628906b066418d8ac8",
            "9eaae92022d54f9a87ddbf03e1e88933",
            "6a8484b52bd0452da3f447caa875f83f",
            "bbcb8fb19764405da21f5038aaccc361",
            "a0ceadb4e2014f68991626e867e12a6a",
            "bc955cc79af1466fa3c1abb3d4fca086",
            "592ef782956d4583b88f9629a41fb205",
            "90ab06abe29649f3b3392cd407af450b",
            "0eb5e0d77b3249aeb0dd93f7b1f9e391",
            "7317deb67d4441bd82560ff77d7ae5a4",
            "32b93181b78d491297ba924270e9b9ca",
            "135d8beccf21438aa4a698f3e4ece8de",
            "937abcbd86c5441ba9a2be037cd88995",
            "0f392cc0a0dc45ecadea98aa0650d6e8",
            "4c8340f5b5704a4aa36539a1a94917ce",
            "6ddf1fbaf1f947cbaeab0a76745efe82",
            "1a20ff983b914ed69cc9e4b8e044e69e",
            "3bcea574e6d24a5da4bd708f6b947ddb",
            "098e7b0972934e7fbf46bbc961a5eef7",
            "99df6b38ec6a4eb08200215073364087",
            "2f2cdd3696f24bebaef6e82d68e43193",
            "6b1f986323d94728a9599ef8f3c695a6",
            "b9f9fb2301cb463381569ebcb29a7795",
            "ff8fad3b15f6459cb7c8eacd5b16f9e4",
            "d9f7502a121e4d889e5c59a4afc1a2db",
            "0ac0d68e7ec448b78c757be30a716d2f",
            "c64fc7c2a73c43dc9c0132712dd0446d",
            "734f57b7cbb5446cae09d636ee8f9822",
            "ef2af4bd0338494498e9d2866a2d4ae9",
            "8d37f76621684973a7e3a022476e55bb",
            "77e2a0aa98674f6199d0af92d119b2ce",
            "a13df89b9622460c9a6906fea7b189bf",
            "961c987f7a6843418746bb26158c3a28",
            "7f5a29bc57c74aef857767fc30e6b3c1",
            "5333a897833849a7823dc887425ec891",
            "cef1bf4690fc4db4bb8710c383d3af68",
            "ea87fe31581346a996c6f98dda92366f",
            "eca60e51d664407d9def45623f682c77",
            "edc4e95f83ba47b4bcba22801038bd4e",
            "1d530217c19040e6a635692840bd8931",
            "2bf29cd16ef449668b94c914d9240870",
            "346172f2bde44d30a7a5b173c31f26d6",
            "3ede3a11c6714ffda8d30a555ff37d57",
            "ec82ad6dacb0425086b729c7738862b3"
          ]
        },
        "id": "5LYB960ycZcl",
        "outputId": "1766af94-50fc-4afe-8ba3-bf4f0cefcd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model/tokenizer: Intel/deberta-v3-base-mrpc ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/412 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c274ed5d638b41ecba477cb38fb75644"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d2be1d3c77f4f488230546661b0a11e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c21c379d22324010bb50e678bcf7ab4f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d70d9cc5b04a43b282ac0650083587a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e1c72076a75f45628906b066418d8ac8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "135d8beccf21438aa4a698f3e4ece8de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9f9fb2301cb463381569ebcb29a7795"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/738M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f5a29bc57c74aef857767fc30e6b3c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_dipper_val] Searching for DIPPER valid/dev files under: /content/dipper_data\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx.tsv -> 1483\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx.tsv -> 1479\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx.tsv -> 1478\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx.tsv -> 1489\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx.tsv -> 1487\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx.tsv -> 1471\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx.tsv -> 1469\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx.tsv -> 1482\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx.tsv -> 1415\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx.tsv -> 1438\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx.tsv -> 1473\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/ctx_all.tsv\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx.tsv -> 1433\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx.tsv -> 1462\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "[gather_dipper_pos_val] Total valid-like files found: 176\n",
            "[load_dipper_val] Loaded DIPPER val: 8000 samples (label dist: {1: 5327, 0: 2673})\n",
            "Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-599152110.py:152: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n",
            "/tmp/ipython-input-599152110.py:152: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  HC3 train: no_ctx=60205 ctx=60205\n",
            "Built HC3-eval: 8000 samples\n",
            "Loaded custom CSV: 90 (pos/neg: {1: 60, 0: 30})\n",
            "\n",
            "Evaluating DIPPER_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-599152110.py:277: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/deberta_v3_mrpc/dipper_val_confusion_matrix.png\n",
            "Saved /content/output/deberta_v3_mrpc/dipper_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.45      1.00      0.62      2673\n",
            "    Paraphrase       0.99      0.38      0.55      5327\n",
            "\n",
            "      accuracy                           0.58      8000\n",
            "     macro avg       0.72      0.69      0.58      8000\n",
            "  weighted avg       0.81      0.58      0.57      8000\n",
            "\n",
            "\n",
            "Evaluating HC3_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-599152110.py:277: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/deberta_v3_mrpc/hc3_val_confusion_matrix.png\n",
            "Saved /content/output/deberta_v3_mrpc/hc3_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.35      0.99      0.52      2664\n",
            "    Paraphrase       0.93      0.10      0.17      5336\n",
            "\n",
            "      accuracy                           0.39      8000\n",
            "     macro avg       0.64      0.54      0.35      8000\n",
            "  weighted avg       0.74      0.39      0.29      8000\n",
            "\n",
            "Saved summary.json to /content/output/deberta_v3_mrpc\n",
            "\n",
            "Evaluating CUSTOM_CSV (90 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-599152110.py:277: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/deberta_v3_mrpc/custom_csv_confusion_matrix.png\n",
            "Saved /content/output/deberta_v3_mrpc/custom_csv_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       1.00      0.93      0.97        30\n",
            "    Paraphrase       0.97      1.00      0.98        60\n",
            "\n",
            "      accuracy                           0.98        90\n",
            "     macro avg       0.98      0.97      0.97        90\n",
            "  weighted avg       0.98      0.98      0.98        90\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            sentence1  \\\n",
              "0   The possibility of approximating a continuous ...   \n",
              "1   State-of-the-art object detection networks dep...   \n",
              "2   I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "3   Our evolutionary history suggests that there w...   \n",
              "4   The possibility of approximating a continuous ...   \n",
              "..                                                ...   \n",
              "85  The possibility of approximating a continuous ...   \n",
              "86  In fact, science and technology are clearly di...   \n",
              "87  I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "88  Our evolutionary history suggests that there w...   \n",
              "89  We study a novel machine learning (ML) problem...   \n",
              "\n",
              "                                            sentence2  label  pred  \\\n",
              "0   Several studies have examined the ability of a...      1     1   \n",
              "1   Leading object detection networks rely on regi...      1     1   \n",
              "2   I had resolved not to write a \"Top Whatever\" b...      1     1   \n",
              "3   Indeed, science and technology are distinctly ...      0     0   \n",
              "4   Numerous research papers have investigated the...      1     1   \n",
              "..                                                ...    ...   ...   \n",
              "85  A feedforward neural network with one hidden l...      1     1   \n",
              "86  In a recent opinion piece in The Conversation,...      0     0   \n",
              "87  We investigate a new machine learning problem ...      0     0   \n",
              "88  Our evolutionary history indicates that there ...      1     1   \n",
              "89  We investigate a new machine learning problem ...      1     1   \n",
              "\n",
              "    prob_paraphrase  \n",
              "0          0.999547  \n",
              "1          0.999545  \n",
              "2          0.999384  \n",
              "3          0.002765  \n",
              "4          0.999544  \n",
              "..              ...  \n",
              "85         0.999539  \n",
              "86         0.002277  \n",
              "87         0.002738  \n",
              "88         0.999542  \n",
              "89         0.999515  \n",
              "\n",
              "[90 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2c10e0b-dbf8-44af-99bd-9cb7ee8e17bd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_paraphrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Several studies have examined the ability of a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>State-of-the-art object detection networks dep...</td>\n",
              "      <td>Leading object detection networks rely on regi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>I had resolved not to write a \"Top Whatever\" b...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Indeed, science and technology are distinctly ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Numerous research papers have investigated the...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>A feedforward neural network with one hidden l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>In fact, science and technology are clearly di...</td>\n",
              "      <td>In a recent opinion piece in The Conversation,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.002738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Our evolutionary history indicates that there ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>We study a novel machine learning (ML) problem...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.999515</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2c10e0b-dbf8-44af-99bd-9cb7ee8e17bd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2c10e0b-dbf8-44af-99bd-9cb7ee8e17bd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2c10e0b-dbf8-44af-99bd-9cb7ee8e17bd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4a2dd835-76f8-47bc-babf-a0aec5b2b3c0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4a2dd835-76f8-47bc-babf-a0aec5b2b3c0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4a2dd835-76f8-47bc-babf-a0aec5b2b3c0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"No custom CSV results to display\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Andrew Ng hands me a tiny device that wraps around my ear and connects to a smartphone via a small cable. It looks like a throwback---a smartphone earpiece without a Bluetooth connection. But it's really a glimpse of the future. In a way, this tiny device allows the blind to see.\",\n          \"The possibility of approximating a continuous function on a compact subset of the real line by a feedforward single hidden layer neural network with a sigmoidal activation function has been studied in many papers. \",\n          \"We study a novel machine learning (ML) problem setting of sequentially allocating small subsets of training data amongst a large set of classifiers. The goal is to select a classifier that will give near-optimal accuracy when trained on all data, while also minimizing the cost of misallocated samples.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Several studies have examined the ability of a single hidden layer feedforward neural network with a sigmoidal activation function to approximate a continuous function on a compact subset of the real line.\",\n          \"Professor Lord Krebs stated in a recent opinion article in The Conversation that \\\"accurate reporting of science matters\\\" and that scientists have a professional obligation to \\\"challenge poor media reporting on climate change\\\".\",\n          \"I promise I had no intention of writing a \\\"Top Whatevers of 2015\\\" blog post this year, but then Slate's Benevolent Overlords requested I write one, and what option did I have? They're benevolent, yet they remain overlords. Additionally, I'm fond of them.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_paraphrase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4640850965212278,\n        \"min\": 0.0019686094019562006,\n        \"max\": 0.999561607837677,\n        \"num_unique_values\": 85,\n        \"samples\": [\n          0.003372612874954939,\n          0.9995470643043518\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved custom_results.csv to /content/output/deberta_v3_mrpc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## viswadarshan06/pd-mpnet"
      ],
      "metadata": {
        "id": "854LVle1iHri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import torch\n",
        "\n",
        "# Delete model, tokenizer, and any large tensors\n",
        "del model\n",
        "del tokenizer\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "id": "cFRe6NHGw8kZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Optional, List\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import (accuracy_score, precision_recall_fscore_support,\n",
        "                            matthews_corrcoef, confusion_matrix, roc_auc_score,\n",
        "                            roc_curve, classification_report)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuration\n",
        "MODEL_NAME = \"viswadarshan06/pd-mpnet\"\n",
        "OUTPUT_ROOT = Path(\"./output/pd_mpnet\").resolve()\n",
        "OUTPUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "BATCH_SIZE = 64\n",
        "MAX_LENGTH = 256\n",
        "USE_MIXED_PRECISION = True\n",
        "\n",
        "# ----- cleaning/parsing helpers -----\n",
        "def clean_sentence(sent: str) -> str:\n",
        "    s = str(sent)\n",
        "    s = re.sub(r\"lexical\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = re.sub(r\"order\\s*=\\s*\\d+\", \"\", s, flags=re.IGNORECASE)\n",
        "    s = s.replace(\"<sent>\", \" \")\n",
        "    matches = re.findall(r'\"([^\"]+)\"', s)\n",
        "    if matches:\n",
        "        s = \" \".join(matches)\n",
        "    s = re.sub(r\"\\s+\", \" \", s)\n",
        "    s = s.replace(\", ,\", \",\").strip()\n",
        "    return s\n",
        "\n",
        "def parse_dipper_tsv(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    if df is None or df.shape[1] < 2:\n",
        "        return pd.DataFrame(columns=[\"sentence1\", \"sentence2\", \"label\"])\n",
        "    c1, c2 = df.columns[0], df.columns[1]\n",
        "    s1 = df[c1].astype(str).map(clean_sentence)\n",
        "    s2 = df[c2].astype(str).map(clean_sentence)\n",
        "    out = pd.DataFrame({\"sentence1\": s1, \"sentence2\": s2})\n",
        "    out = out[(out[\"sentence1\"].str.len() > 8) & (out[\"sentence2\"].str.len() > 8)].copy()\n",
        "    out[\"label\"] = 1\n",
        "    out.dropna(inplace=True)\n",
        "    out.reset_index(drop=True, inplace=True)\n",
        "    return out\n",
        "\n",
        "def _read_tsv(path: str, nrows: Optional[int] = None) -> Optional[pd.DataFrame]:\n",
        "    try:\n",
        "        return pd.read_csv(path, sep=\"\\t\", nrows=nrows, header=None, engine=\"python\", quoting=3)\n",
        "    except Exception:\n",
        "        try:\n",
        "            return pd.read_csv(path, sep=\"\\t\", nrows=nrows, engine=\"python\")\n",
        "        except Exception:\n",
        "            return None\n",
        "\n",
        "def gather_dipper_pos_val(root: str, nrows_val: Optional[int] = 1500) -> List[pd.DataFrame]:\n",
        "    out = []\n",
        "    if not os.path.exists(root):\n",
        "        print(f\"[gather_dipper_pos_val] DIPPER root not found: {root}\")\n",
        "        return out\n",
        "\n",
        "    def is_valid_file(fname: str) -> bool:\n",
        "        lower = fname.lower()\n",
        "        if \"train\" in lower:\n",
        "            return False\n",
        "        if \"valid\" in lower or \"dev\" in lower or \"ctx_all\" in lower or \"no_ctx_all\" in lower:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    found_files = []\n",
        "    for dirpath, dirnames, filenames in os.walk(root):\n",
        "        base = os.path.basename(dirpath)\n",
        "        if not base.startswith(\"sents_\"):\n",
        "            continue\n",
        "        for fname in filenames:\n",
        "            if not fname.lower().endswith(\".tsv\"):\n",
        "                continue\n",
        "            if is_valid_file(fname):\n",
        "                fpath = os.path.join(dirpath, fname)\n",
        "                found_files.append(fpath)\n",
        "                try:\n",
        "                    df_raw = _read_tsv(fpath, nrows=nrows_val)\n",
        "                    df = parse_dipper_tsv(df_raw) if df_raw is not None else None\n",
        "                    if df is not None and len(df) > 0:\n",
        "                        out.append(df)\n",
        "                        print(f\"  ✓ found DIPPER valid-like: {os.path.relpath(fpath, start=root)} -> {len(df)}\")\n",
        "                    else:\n",
        "                        print(f\"  ○ read but no usable rows: {os.path.relpath(fpath, start=root)}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  ! failed reading {fpath}: {e}\")\n",
        "\n",
        "    if not found_files:\n",
        "        print(f\"[gather_dipper_pos_val] No valid/dev files found under {root}.\")\n",
        "    else:\n",
        "        print(f\"[gather_dipper_pos_val] Total valid-like files found: {len(found_files)}\")\n",
        "\n",
        "    return out\n",
        "\n",
        "def add_negatives(df: pd.DataFrame, ratio=1.0, seed=42) -> pd.DataFrame:\n",
        "    pos = df.copy().reset_index(drop=True)\n",
        "    n = len(pos)\n",
        "    if n < 4:\n",
        "        return pos\n",
        "    rng = np.random.default_rng(seed)\n",
        "    idx = rng.permutation(n)\n",
        "    half = n // 2\n",
        "    neg = pd.DataFrame({\n",
        "        \"sentence1\": pos.loc[idx[:half], \"sentence1\"].values,\n",
        "        \"sentence2\": pos.loc[idx[-half:], \"sentence2\"].values,\n",
        "        \"label\": 0\n",
        "    })\n",
        "    if len(neg) > int(len(pos) * ratio):\n",
        "        neg = neg.sample(int(len(pos) * ratio), random_state=seed)\n",
        "    pos[\"label\"] = 1\n",
        "    out = pd.concat([pos, neg], ignore_index=True).sample(frac=1.0, random_state=seed).reset_index(drop=True)\n",
        "    return out\n",
        "\n",
        "def load_dipper_val(dipper_root: str = \"/content/dipper_data\", val_size_limit: int = 8000) -> pd.DataFrame:\n",
        "    print(f\"[load_dipper_val] Searching for DIPPER valid/dev files under: {dipper_root}\")\n",
        "    pos_list = gather_dipper_pos_val(dipper_root)\n",
        "    if not pos_list:\n",
        "        raise RuntimeError(\"No DIPPER valid-like files found under dipper_root. Check path and filename conventions.\")\n",
        "    pos_all = pd.concat(pos_list, ignore_index=True)\n",
        "    full = add_negatives(pos_all, ratio=1.0)\n",
        "    val_size = min(val_size_limit, max(2000, int(0.1 * len(full))))\n",
        "    val_df = full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[load_dipper_val] Loaded DIPPER val: {len(val_df)} samples (label dist: {val_df['label'].value_counts().to_dict()})\")\n",
        "    return val_df[0:8000]\n",
        "\n",
        "# HC3 helpers\n",
        "def to_list_safely(x):\n",
        "    if x is None: return []\n",
        "    try:\n",
        "        if pd.isna(x): return []\n",
        "    except Exception:\n",
        "        pass\n",
        "    if isinstance(x, (list, tuple)):\n",
        "        return [str(e).strip() for e in x if str(e).strip()]\n",
        "    if isinstance(x, np.ndarray):\n",
        "        return [str(e).strip() for e in x.tolist() if str(e).strip()]\n",
        "    s = str(x).strip()\n",
        "    return [s] if s else []\n",
        "\n",
        "def make_pairs_from_hc3_split(ds_split, add_context: bool, cartesian: bool = True):\n",
        "    df = ds_split.to_pandas()\n",
        "    rows = []\n",
        "    human_col = \"human_answers\" if \"human_answers\" in df.columns else \"human_answers\"\n",
        "    ai_col = \"chatgpt_answers\" if \"chatgpt_answers\" in df.columns else \"chatgpt_answers\"\n",
        "    q_col = \"question\" if \"question\" in df.columns else None\n",
        "    for _, r in df.iterrows():\n",
        "        q = \"\"\n",
        "        if q_col is not None and q_col in r:\n",
        "            q = str(r[q_col]).strip()\n",
        "        human_list = to_list_safely(r.get(human_col))\n",
        "        ai_list = to_list_safely(r.get(ai_col))\n",
        "        if not human_list or not ai_list:\n",
        "            continue\n",
        "        prefix = \"lexical = NA, order = NA\"\n",
        "        if cartesian:\n",
        "            for h in human_list:\n",
        "                for a in ai_list:\n",
        "                    if add_context and q:\n",
        "                        col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                    else:\n",
        "                        col0 = f\"{prefix} {h}\"\n",
        "                    rows.append((col0, a))\n",
        "        else:\n",
        "            k = min(len(human_list), len(ai_list))\n",
        "            for i in range(k):\n",
        "                h = human_list[i]; a = ai_list[i]\n",
        "                if add_context and q:\n",
        "                    col0 = f\"{prefix}  <sent> {q} </sent> {h}\"\n",
        "                else:\n",
        "                    col0 = f\"{prefix} {h}\"\n",
        "                rows.append((col0, a))\n",
        "    return pd.DataFrame(rows, columns=[0, 1])\n",
        "\n",
        "def build_hc3_tsvs(cartesian=True):\n",
        "    print(\"Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\")\n",
        "    hc3 = load_dataset(\"Hello-SimpleAI/HC3\", \"all\")\n",
        "    all_splits = {}\n",
        "    for split in hc3.keys():\n",
        "        df_no_ctx = make_pairs_from_hc3_split(hc3[split], add_context=False, cartesian=cartesian)\n",
        "        df_no_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_no_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_no_ctx\"] = df_no_ctx\n",
        "        df_ctx = make_pairs_from_hc3_split(hc3[split], add_context=True, cartesian=cartesian)\n",
        "        df_ctx.columns = [\"sentence1\", \"sentence2\"]\n",
        "        df_ctx[\"label\"] = 1\n",
        "        all_splits[f\"hc3_{split}_ctx\"] = df_ctx\n",
        "        print(f\"  HC3 {split}: no_ctx={len(df_no_ctx)} ctx={len(df_ctx)}\")\n",
        "    if len(all_splits) == 0:\n",
        "        raise RuntimeError(\"HC3 had no splits.\")\n",
        "    combined = pd.concat(list(all_splits.values()), ignore_index=True)\n",
        "    combined_full = add_negatives(combined, ratio=1.0)\n",
        "    val_size = min(8000, max(2000, int(0.1 * len(combined_full))))\n",
        "    val_df = combined_full.sample(val_size, random_state=42).reset_index(drop=True)\n",
        "    print(f\"Built HC3-eval: {len(val_df)} samples\")\n",
        "    return val_df\n",
        "\n",
        "# ----- Torch Dataset -----\n",
        "class PairEvalDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, tokenizer, max_length=256):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.tok = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self, idx):\n",
        "        r = self.df.loc[idx]\n",
        "        a = str(r[\"sentence1\"])\n",
        "        b = str(r[\"sentence2\"])\n",
        "        toks = self.tok(a, b, truncation=True, max_length=self.max_length, padding=\"max_length\", return_tensors=\"pt\")\n",
        "        item = {k: v.squeeze(0) for k, v in toks.items()}\n",
        "        item[\"label\"] = torch.tensor(int(r[\"label\"]), dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# ----- Evaluation functions -----\n",
        "def save_confusion_matrix(cm: np.ndarray, dataset_name: str, output_dir: str, normalize: bool = False):\n",
        "    fmt = 'd'\n",
        "    cbar_label = 'Count'\n",
        "    title = f\"{dataset_name} - Confusion Matrix\"\n",
        "    cm_plot = cm\n",
        "    if normalize:\n",
        "        cm_plot = cm.astype(float)\n",
        "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
        "        cm_plot = np.divide(cm_plot, row_sums, where=row_sums != 0)\n",
        "        fmt = '.2f'\n",
        "        cbar_label = 'Proportion'\n",
        "        title = f\"{dataset_name} - Normalized Confusion Matrix\"\n",
        "    plt.figure(figsize=(5.5,4.5))\n",
        "    sns.heatmap(cm_plot, annot=True, fmt=fmt, cmap='Blues',\n",
        "                xticklabels=['Not Paraphrase','Paraphrase'], yticklabels=['Not Paraphrase','Paraphrase'],\n",
        "                cbar_kws={'label': cbar_label})\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    suffix = '_normalized' if normalize else ''\n",
        "    fname = os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_confusion_matrix{suffix}.png\")\n",
        "    plt.savefig(fname, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {fname}\")\n",
        "\n",
        "def evaluate_and_save(model, tokenizer, df: pd.DataFrame, dataset_name: str, output_dir: str, batch_size: int = 64, device: torch.device = DEVICE):\n",
        "    if df is None or len(df) == 0:\n",
        "        print(f\"Skipping {dataset_name} - no data\")\n",
        "        return None, (None, None)\n",
        "    print(f\"\\nEvaluating {dataset_name} ({len(df)} samples)\")\n",
        "    ds = PairEvalDataset(df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "    model.to(device); model.eval()\n",
        "    all_preds = []; all_labels = []; all_probs = []\n",
        "    use_bf16 = torch.cuda.is_available() and torch.cuda.get_device_capability(0)[0] >= 8\n",
        "    amp_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "    with torch.no_grad():\n",
        "        with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n",
        "            for batch in loader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                token_type_ids = batch.get('token_type_ids', None)\n",
        "                if token_type_ids is not None:\n",
        "                    token_type_ids = token_type_ids.to(device)\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "                else:\n",
        "                    out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "                logits = out.logits\n",
        "                probs = F.softmax(logits, dim=-1)[:, 1].cpu().numpy()\n",
        "                preds = (probs > 0.5).astype(int)\n",
        "                all_preds.extend(preds.tolist())\n",
        "                all_labels.extend(batch['label'].cpu().numpy().tolist())\n",
        "                all_probs.extend(probs.tolist())\n",
        "    acc = accuracy_score(all_labels, all_preds)\n",
        "    p, r, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='binary', zero_division=0)\n",
        "    mcc = matthews_corrcoef(all_labels, all_preds) if len(set(all_labels))>1 else 0.0\n",
        "    cm = confusion_matrix(all_labels, all_preds, labels=[0,1])\n",
        "    auc = None; fpr = None; tpr = None; tpr_1pct = None\n",
        "    try:\n",
        "        auc = float(roc_auc_score(all_labels, all_probs))\n",
        "        fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
        "        if len(fpr)>1:\n",
        "            tpr_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "    except Exception:\n",
        "        pass\n",
        "    metrics = {\n",
        "        'dataset': dataset_name,\n",
        "        'accuracy': float(acc),\n",
        "        'precision': float(p),\n",
        "        'recall': float(r),\n",
        "        'f1': float(f1),\n",
        "        'mcc': float(mcc),\n",
        "        'auc': auc,\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'samples': len(df),\n",
        "        'tpr_at_1pct_fpr': tpr_1pct,\n",
        "        'fpr': fpr.tolist() if fpr is not None else None,\n",
        "        'tpr': tpr.tolist() if tpr is not None else None\n",
        "    }\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=False)\n",
        "    save_confusion_matrix(cm, dataset_name, output_dir, normalize=True)\n",
        "    with open(os.path.join(output_dir, f\"{dataset_name.lower().replace(' ','_')}_metrics.json\"), \"w\") as fh:\n",
        "        json.dump(metrics, fh, indent=2)\n",
        "    print(classification_report(all_labels, all_preds, target_names=['Not Paraphrase','Paraphrase']))\n",
        "    return metrics, (all_labels, all_probs)\n",
        "\n",
        "# ----- Load model & tokenizer -----\n",
        "print(f\"Loading model/tokenizer: {MODEL_NAME} ...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "model.to(DEVICE)\n",
        "\n",
        "# ----- Prepare datasets -----\n",
        "try:\n",
        "    dipper_val = load_dipper_val(\"/content/dipper_data\")\n",
        "except Exception as e:\n",
        "    print(\"Warning: DIPPER load failed:\", e)\n",
        "    dipper_val = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "try:\n",
        "    hc3_df = build_hc3_tsvs(cartesian=True)\n",
        "except Exception as e:\n",
        "    print(\"Warning: HC3 load failed:\", e)\n",
        "    hc3_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "# Custom CSV\n",
        "CUSTOM_CSV_PATH = \"/content/custom_paraphrases.csv\"\n",
        "custom_df = None\n",
        "if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "    cdf = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "    if {\"original_sentence\",\"paraphrased_sentence\"}.issubset(set(cdf.columns)):\n",
        "        custom_df = pd.DataFrame({\n",
        "            \"sentence1\": cdf[\"original_sentence\"].astype(str),\n",
        "            \"sentence2\": cdf[\"paraphrased_sentence\"].astype(str),\n",
        "            \"label\": 1\n",
        "        })\n",
        "        custom_eval_df = add_negatives(custom_df, ratio=1.0)\n",
        "        print(f\"Loaded custom CSV: {len(custom_eval_df)} (pos/neg: {custom_eval_df['label'].value_counts().to_dict()})\")\n",
        "    else:\n",
        "        print(\"Custom CSV missing required columns. Skipping custom.\")\n",
        "        custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "else:\n",
        "    print(f\"Custom CSV not found at {CUSTOM_CSV_PATH}. Skipping custom.\")\n",
        "    custom_eval_df = pd.DataFrame(columns=[\"sentence1\",\"sentence2\",\"label\"])\n",
        "\n",
        "OUT = OUTPUT_ROOT\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# ----- Evaluate DIPPER and HC3 -----\n",
        "all_metrics = []\n",
        "roc_entries = []\n",
        "for df, name in [(dipper_val, \"DIPPER_VAL\"), (hc3_df, \"HC3_VAL\")]:\n",
        "    if df is None or len(df)==0:\n",
        "        print(f\"Skipping {name} - no data\")\n",
        "        continue\n",
        "    metrics, (labels, probs) = evaluate_and_save(model, tokenizer, df, name, str(OUT), batch_size=BATCH_SIZE)\n",
        "    if metrics:\n",
        "        all_metrics.append(metrics)\n",
        "        if metrics.get('auc') is not None and metrics.get('fpr') is not None:\n",
        "            roc_entries.append({\n",
        "                'dataset': name,\n",
        "                'fpr': np.array(metrics['fpr']),\n",
        "                'tpr': np.array(metrics['tpr']),\n",
        "                'auc': metrics['auc'],\n",
        "                'accuracy': metrics['accuracy']\n",
        "            })\n",
        "\n",
        "with open(os.path.join(OUT, \"summary.json\"), \"w\") as fh:\n",
        "    json.dump(all_metrics, fh, indent=2)\n",
        "print(f\"Saved summary.json to {OUT}\")\n",
        "\n",
        "# ----- Plot ROC curves comparison -----\n",
        "if len(roc_entries) > 0:\n",
        "    plt.figure(figsize=(8,6))\n",
        "    cmap = plt.get_cmap('tab10')\n",
        "    lines = []\n",
        "    labels_list = []\n",
        "    for i, entry in enumerate(roc_entries):\n",
        "        color = cmap(i % 10)\n",
        "        fpr = entry['fpr']\n",
        "        tpr = entry['tpr']\n",
        "        auc_val = entry['auc']\n",
        "        acc_val = entry['accuracy']\n",
        "\n",
        "        if len(fpr) == 0 or len(tpr) == 0:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            tpr_at_1pct = float(np.interp(0.01, fpr, tpr))\n",
        "        except Exception:\n",
        "            tpr_at_1pct = 0.0\n",
        "        plt.plot(fpr, tpr, label=None, color=color, linewidth=2)\n",
        "        legend_label = f\"{entry['dataset']} (AUC={auc_val:.3f}, TPR@1%FPR={tpr_at_1pct:.3f}, Acc={acc_val:.3f})\"\n",
        "        lines.append(plt.Line2D([0],[0], color=color, lw=2))\n",
        "        labels_list.append(legend_label)\n",
        "\n",
        "    plt.plot([0,1],[0,1], linestyle='--', color='gray', linewidth=1.5, label='Random')\n",
        "    plt.xlim([0.0,1.0])\n",
        "    plt.ylim([0.0,1.05])\n",
        "    plt.xlabel('False Positive Rate', fontsize=12)\n",
        "    plt.ylabel('True Positive Rate', fontsize=12)\n",
        "    plt.title('ROC Curves Comparison', fontsize=14, fontweight='bold')\n",
        "    plt.legend(lines + [plt.Line2D([0],[0], color='gray', lw=1.5, linestyle='--')],\n",
        "               labels_list + ['Random'], loc='lower right', fontsize=10)\n",
        "    plt.grid(alpha=0.3)\n",
        "    roc_path = os.path.join(OUT, 'roc_comparison.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(roc_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {roc_path}\")\n",
        "else:\n",
        "    print('No ROC data available for plotting.')\n",
        "\n",
        "# ----- Plot performance metrics comparison -----\n",
        "if len(all_metrics) > 1:\n",
        "    comp_df = pd.DataFrame(all_metrics)\n",
        "    comp_df_sorted = comp_df.set_index('dataset')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12,6))\n",
        "    comp_df_sorted[['accuracy','precision','recall','f1','mcc','auc','tpr_at_1pct_fpr']].plot(\n",
        "        kind='bar', ax=ax, width=0.8)\n",
        "    plt.title('Performance Metrics Comparison Across Datasets', fontsize=14, fontweight='bold')\n",
        "    plt.ylabel('Score', fontsize=12)\n",
        "    plt.xlabel('Dataset', fontsize=12)\n",
        "    plt.ylim(0,1.05)\n",
        "    plt.legend(title='Metrics', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.grid(axis='y', alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    comp_path = os.path.join(OUT, 'metrics_comparison.png')\n",
        "    plt.savefig(comp_path, dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(f\"Saved {comp_path}\")\n",
        "\n",
        "# ----- Print and save summary table -----\n",
        "summary_df = pd.DataFrame(all_metrics)\n",
        "if not summary_df.empty:\n",
        "    display_cols = ['dataset','accuracy','precision','recall','f1','mcc',\n",
        "                'auc','tpr_at_1pct_fpr','samples']\n",
        "    print('\\n' + '='*80)\n",
        "    print('SUMMARY TABLE')\n",
        "    print('='*80)\n",
        "    print(summary_df[display_cols].round(4).to_string(index=False))\n",
        "    print('='*80)\n",
        "    summary_df.to_csv(os.path.join(OUT, 'summary.csv'), index=False)\n",
        "    print(f\"\\nSaved summary table to {os.path.join(OUT, 'summary.csv')}\")\n",
        "\n",
        "# ----- Evaluate custom CSV and create per-model analysis -----\n",
        "if custom_eval_df is not None and len(custom_eval_df)>0:\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"CUSTOM CSV EVALUATION - PER-MODEL ANALYSIS\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    metrics_c, (labels_c, probs_c) = evaluate_and_save(model, tokenizer, custom_eval_df, \"CUSTOM_CSV\", str(OUT), batch_size=BATCH_SIZE)\n",
        "\n",
        "    # Get predictions for all samples\n",
        "    ds_custom = PairEvalDataset(custom_eval_df, tokenizer, max_length=MAX_LENGTH)\n",
        "    loader = DataLoader(ds_custom, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    preds_list = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            input_ids = batch['input_ids'].to(DEVICE)\n",
        "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
        "            out = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            probs = F.softmax(out.logits, dim=-1)[:,1].cpu().numpy()\n",
        "            preds = (probs > 0.5).astype(int)\n",
        "            for i in range(len(preds)):\n",
        "                preds_list.append({'pred': int(preds[i]), 'prob_paraphrase': float(probs[i])})\n",
        "\n",
        "    # Combine with original data\n",
        "    report_df = custom_eval_df.copy().reset_index(drop=True)\n",
        "    preds_df = pd.DataFrame(preds_list)\n",
        "    display_df = pd.concat([report_df, preds_df], axis=1)\n",
        "\n",
        "    # Load original CSV to get model names\n",
        "    if os.path.isfile(CUSTOM_CSV_PATH):\n",
        "        orig_csv = pd.read_csv(CUSTOM_CSV_PATH)\n",
        "        if 'model_name' in orig_csv.columns:\n",
        "            display_df['model_name'] = orig_csv['model_name'].values[:len(display_df)]\n",
        "\n",
        "            # Calculate per-model metrics\n",
        "            model_metrics = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                labels_m = model_data['label'].values\n",
        "                preds_m = model_data['pred'].values\n",
        "\n",
        "                acc = accuracy_score(labels_m, preds_m)\n",
        "                p, r, f1, _ = precision_recall_fscore_support(labels_m, preds_m, average='binary', zero_division=0)\n",
        "\n",
        "                model_metrics.append({\n",
        "                    'Model': model_name,\n",
        "                    'Precision (%)': p * 100,\n",
        "                    'Recall (%)': r * 100,\n",
        "                    'F1-Score (%)': f1 * 100,\n",
        "                    'Accuracy (%)': acc * 100,\n",
        "                    'Samples': len(model_data)\n",
        "                })\n",
        "\n",
        "            model_perf_df = pd.DataFrame(model_metrics)\n",
        "\n",
        "            # Display and save per-model table\n",
        "            print(\"\\nPer-Model Performance:\")\n",
        "            print(model_perf_df.round(2).to_string(index=False))\n",
        "            model_perf_df.to_csv(os.path.join(OUT, \"per_model_metrics.csv\"), index=False)\n",
        "            print(f\"\\nSaved per-model metrics to {os.path.join(OUT, 'per_model_metrics.csv')}\")\n",
        "\n",
        "            # Plot per-model performance\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            x = np.arange(len(model_perf_df))\n",
        "            width = 0.2\n",
        "\n",
        "            ax.bar(x - 1.5*width, model_perf_df['Precision (%)'], width, label='Precision', alpha=0.8)\n",
        "            ax.bar(x - 0.5*width, model_perf_df['Recall (%)'], width, label='Recall', alpha=0.8)\n",
        "            ax.bar(x + 0.5*width, model_perf_df['F1-Score (%)'], width, label='F1-Score', alpha=0.8)\n",
        "            ax.bar(x + 1.5*width, model_perf_df['Accuracy (%)'], width, label='Accuracy', alpha=0.8)\n",
        "\n",
        "            ax.set_ylabel('Score (%)', fontsize=12)\n",
        "            ax.set_xlabel('Model', fontsize=12)\n",
        "            ax.set_title('Paraphrase Detection Performance by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xticks(x)\n",
        "            ax.set_xticklabels(model_perf_df['Model'], rotation=45, ha='right')\n",
        "            ax.legend()\n",
        "            ax.set_ylim(0, 105)\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            model_plot_path = os.path.join(OUT, 'per_model_performance.png')\n",
        "            plt.savefig(model_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved per-model plot to {model_plot_path}\")\n",
        "\n",
        "            # Plot average probability scores by model\n",
        "            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "            model_probs = display_df.groupby('model_name')['prob_paraphrase'].agg(['mean', 'std'])\n",
        "            model_probs = model_probs.sort_values('mean', ascending=False)\n",
        "\n",
        "            ax.barh(model_probs.index, model_probs['mean'], xerr=model_probs['std'],\n",
        "                   capsize=5, alpha=0.7, color='steelblue')\n",
        "            ax.set_xlabel('Average Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Model', fontsize=12)\n",
        "            ax.set_title('Average Paraphrase Detection Confidence by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.set_xlim(0, 1)\n",
        "            ax.grid(axis='x', alpha=0.3)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            prob_plot_path = os.path.join(OUT, 'model_confidence_scores.png')\n",
        "            plt.savefig(prob_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence scores plot to {prob_plot_path}\")\n",
        "\n",
        "            # Heatmap of per-model confusion matrices\n",
        "            n_models = len(model_perf_df)\n",
        "            fig, axes = plt.subplots(1, n_models, figsize=(5*n_models, 4))\n",
        "            if n_models == 1:\n",
        "                axes = [axes]\n",
        "\n",
        "            for idx, model_name in enumerate(display_df['model_name'].unique()):\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                cm = confusion_matrix(model_data['label'], model_data['pred'], labels=[0,1])\n",
        "\n",
        "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx],\n",
        "                           xticklabels=['Not Para','Para'],\n",
        "                           yticklabels=['Not Para','Para'],\n",
        "                           cbar=False)\n",
        "                axes[idx].set_title(f'{model_name}', fontsize=11, fontweight='bold')\n",
        "                axes[idx].set_ylabel('True' if idx == 0 else '', fontsize=10)\n",
        "                axes[idx].set_xlabel('Predicted', fontsize=10)\n",
        "\n",
        "            plt.suptitle('Confusion Matrices by LLM', fontsize=14, fontweight='bold', y=1.02)\n",
        "            plt.tight_layout()\n",
        "\n",
        "            cm_plot_path = os.path.join(OUT, 'model_confusion_matrices.png')\n",
        "            plt.savefig(cm_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confusion matrices plot to {cm_plot_path}\")\n",
        "\n",
        "            # Create error analysis: false positives and false negatives by model\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "            error_data = []\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                fp = ((model_data['label'] == 0) & (model_data['pred'] == 1)).sum()\n",
        "                fn = ((model_data['label'] == 1) & (model_data['pred'] == 0)).sum()\n",
        "                tp = ((model_data['label'] == 1) & (model_data['pred'] == 1)).sum()\n",
        "                tn = ((model_data['label'] == 0) & (model_data['pred'] == 0)).sum()\n",
        "                error_data.append({\n",
        "                    'Model': model_name,\n",
        "                    'False Positives': fp,\n",
        "                    'False Negatives': fn,\n",
        "                    'True Positives': tp,\n",
        "                    'True Negatives': tn\n",
        "                })\n",
        "\n",
        "            error_df = pd.DataFrame(error_data)\n",
        "\n",
        "            # Plot false positives and false negatives\n",
        "            x = np.arange(len(error_df))\n",
        "            width = 0.35\n",
        "\n",
        "            ax1.bar(x - width/2, error_df['False Positives'], width, label='False Positives', color='salmon', alpha=0.8)\n",
        "            ax1.bar(x + width/2, error_df['False Negatives'], width, label='False Negatives', color='lightcoral', alpha=0.8)\n",
        "            ax1.set_ylabel('Count', fontsize=11)\n",
        "            ax1.set_xlabel('Model', fontsize=11)\n",
        "            ax1.set_title('Error Analysis: False Positives vs False Negatives', fontsize=12, fontweight='bold')\n",
        "            ax1.set_xticks(x)\n",
        "            ax1.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax1.legend()\n",
        "            ax1.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            # Plot true positives and true negatives\n",
        "            ax2.bar(x - width/2, error_df['True Positives'], width, label='True Positives', color='mediumseagreen', alpha=0.8)\n",
        "            ax2.bar(x + width/2, error_df['True Negatives'], width, label='True Negatives', color='lightgreen', alpha=0.8)\n",
        "            ax2.set_ylabel('Count', fontsize=11)\n",
        "            ax2.set_xlabel('Model', fontsize=11)\n",
        "            ax2.set_title('Correct Predictions: True Positives vs True Negatives', fontsize=12, fontweight='bold')\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels(error_df['Model'], rotation=45, ha='right')\n",
        "            ax2.legend()\n",
        "            ax2.grid(axis='y', alpha=0.3)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            error_plot_path = os.path.join(OUT, 'model_error_analysis.png')\n",
        "            plt.savefig(error_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved error analysis plot to {error_plot_path}\")\n",
        "\n",
        "            # Distribution of confidence scores by model\n",
        "            fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "            for model_name in display_df['model_name'].unique():\n",
        "                model_data = display_df[display_df['model_name'] == model_name]\n",
        "                ax.hist(model_data['prob_paraphrase'], bins=30, alpha=0.5, label=model_name, edgecolor='black')\n",
        "\n",
        "            ax.set_xlabel('Paraphrase Probability', fontsize=12)\n",
        "            ax.set_ylabel('Frequency', fontsize=12)\n",
        "            ax.set_title('Distribution of Paraphrase Detection Confidence Scores by LLM', fontsize=14, fontweight='bold')\n",
        "            ax.legend()\n",
        "            ax.grid(axis='y', alpha=0.3)\n",
        "            ax.axvline(x=0.5, color='red', linestyle='--', linewidth=2, label='Decision Threshold')\n",
        "            plt.tight_layout()\n",
        "\n",
        "            dist_plot_path = os.path.join(OUT, 'confidence_distribution.png')\n",
        "            plt.savefig(dist_plot_path, dpi=300, bbox_inches='tight')\n",
        "            plt.close()\n",
        "            print(f\"Saved confidence distribution plot to {dist_plot_path}\")\n",
        "\n",
        "    # Save detailed per-sample results\n",
        "    display_df.to_csv(os.path.join(OUT, \"custom_results_detailed.csv\"), index=False)\n",
        "    print(f\"\\nSaved detailed results to {os.path.join(OUT, 'custom_results_detailed.csv')}\")\n",
        "    print(f\"Total samples evaluated: {len(display_df)}\")\n",
        "else:\n",
        "    print(\"\\nNo custom CSV results to display.\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "print(f\"All results saved to: {OUT}\")\n",
        "print(\"\\nGenerated files:\")\n",
        "print(\"  - summary.json, summary.csv: Overall metrics across datasets\")\n",
        "print(\"  - roc_comparison.png: ROC curves for DIPPER and HC3\")\n",
        "print(\"  - metrics_comparison.png: Bar chart comparing all metrics\")\n",
        "print(\"  - per_model_metrics.csv: Performance table by LLM\")\n",
        "print(\"  - per_model_performance.png: Bar chart of metrics by LLM\")\n",
        "print(\"  - model_confidence_scores.png: Average confidence by LLM\")\n",
        "print(\"  - model_confusion_matrices.png: Confusion matrices grid\")\n",
        "print(\"  - model_error_analysis.png: False positive/negative analysis\")\n",
        "print(\"  - confidence_distribution.png: Probability distributions\")\n",
        "print(\"  - custom_results_detailed.csv: Per-sample predictions\")\n",
        "print(\"=\"*80)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "76e784e227e74025819a5785ba1c0e7f",
            "0a84886a4a12434da318020515c5f933",
            "bc6bb180e58443da8ab3b4e6b79616df",
            "e3fc58af685a41768f24bfc2fbb69603",
            "bad1e02e27ed4aeeb620756260b21725",
            "bc3269e0e47b43cba323a3fe99118cea",
            "725b8cf05c4742078cb536a50df00d9b",
            "d881cef4b44e4d408a6976163edbee6e",
            "4da4f1137cfe434bb685534c9f51b009",
            "b95b0ec154814a559aa1d2faf41b9ce0",
            "f21adab98d1b49778ac17e14cf2ae3ec",
            "f0f0c11906484e5d8c6d295d7d4fa778",
            "30673510b9b942b182b2901176daa2c5",
            "ec18121e45af49038c043411d110adc1",
            "02c83dc6e9024df8acad6804a9833284",
            "7ad457413aad41b3a327809198ed4669",
            "a17410ed3aec42668c2a505f1ce275e8",
            "50c8fd59e66d44bfa0f15b023331aef4",
            "c9cde3cce10045099c641b2f3f63afaf",
            "3f3707f9f676482ea15e871a5b5a1ad4",
            "e4c7e966af1f40459fd8a9a494e6e0b8",
            "192322e577a14456b58bf010720c1fe2",
            "ec4a95beef9843cf926ee35b61d6cdac",
            "d9855d530e7a4017bd296845b319416f",
            "af4dcd9d996c43be8448c54c0b101de7",
            "3bfa4da67daf4b9e83842627120253a8",
            "56ee3b3fed7c453f8badbd4c5c1de5ec",
            "855858e70af545eb86f69137de13f74f",
            "85ac9f722b834a15ad46dc50ff34216d",
            "675c3a31b6104766a17a79cbe094b750",
            "f3b0a80fdccf4702911529869258b894",
            "0fb4d406a6774f79975d30b9a1ccea29",
            "8521285e752e4dfaa2920a1f75408e9c",
            "ab45582549264aadb59f86e1ca07ed0f",
            "37bbcb7ac8cd48c6959871850b9f5b76",
            "341e3bbbd3134dfda96b05886c71e156",
            "d75ca3ab1850426097a0be82c01549e6",
            "d30d1637157c4bb887fd5a66431b0419",
            "413c60e55945451b9b7479f7b338954e",
            "ac039ecee36b450792b7a5165444b91a",
            "83723fe44eb04b3592c3132ffb4c9b60",
            "74f88ff046fa459d8785310226e88b32",
            "5b0c303e23f74939a17fb15d058bb073",
            "2f185aa44fec4128b39cc3a98cf0b4e8",
            "bc348ccf06a2455084bbaff5c580bec6",
            "05fa98888cbb47c9b11825057be872ab",
            "60c1426eee914997aa5730f8d883914d",
            "84d480490ae04be39b6ed8f0782a2eeb",
            "1d562938e33c45b58d686acb42e3874f",
            "4fcaf2b18905446996addde57f8427f3",
            "a01086bb99434e5f9affc18634a4f686",
            "d6061a20c45a4672a2178422642dd5a0",
            "f0adfc0eedcd4d699a3fabb65ad77c8b",
            "ffc9fcc977194ffc864b27417ecf50ea",
            "d84fa2314dba456789451495a56e32dc",
            "4d8adebf34ec4ecd85a75ce3844f8505",
            "f40a55c904d34c8499db4ca517e4619c",
            "23451a5e6217471f975532d88af01278",
            "8f53502f291246e1a4ca4be5939f5346",
            "ce3e3665933a43e7a47489fa545be972",
            "79d75c7d3da447e7b129c97197171c0a",
            "8eeb3df58fb5487093301d61c8ca0b03",
            "dc640a051e3b46aeaa99592fcd5b308f",
            "05be776666ec4fedbd2c15ddeacf8961",
            "a7a8725ca88d4ee88003e406295a3671",
            "2de08be02a2e44c3b06174771d9809e6"
          ]
        },
        "id": "4IcxNsiFiM8l",
        "outputId": "5b2e587e-7644-4eaa-eeaf-3b663b1ca46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model/tokenizer: viswadarshan06/pd-mpnet ...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76e784e227e74025819a5785ba1c0e7f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0f0c11906484e5d8c6d295d7d4fa778"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec4a95beef9843cf926ee35b61d6cdac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab45582549264aadb59f86e1ca07ed0f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/698 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc348ccf06a2455084bbaff5c580bec6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4d8adebf34ec4ecd85a75ce3844f8505"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load_dipper_val] Searching for DIPPER valid/dev files under: /content/dipper_data\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_no_ctx.tsv -> 1483\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx.tsv -> 1479\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx.tsv -> 1478\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_no_ctx.tsv -> 1489\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx.tsv -> 1487\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx.tsv -> 1471\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx.tsv -> 1469\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx.tsv -> 1474\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_7/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_no_ctx.tsv -> 1485\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx.tsv -> 1482\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx.tsv -> 1415\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx.tsv -> 1438\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx.tsv -> 1465\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx.tsv -> 1473\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all_small.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_ctx_all.tsv -> 1484\n",
            "  ✓ found DIPPER valid-like: par3/gt_translator/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_webtext/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/pg19/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/wikipedia/sents_3/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_8/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_2/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_4/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_6/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_7/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_9/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_1/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_5/ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/no_ctx_all.tsv\n",
            "  ○ read but no usable rows: par3/out_domain/c4_realnews/sents_3/ctx_all.tsv\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_8/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_2/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_10/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_4/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_6/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_7/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_9/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx.tsv -> 1433\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx.tsv -> 1462\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_ctx_all.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_1/valid_ctrl_no_ctx_all_small.tsv -> 1468\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_5/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all_small.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_ctx_all.tsv -> 1500\n",
            "  ✓ found DIPPER valid-like: par3/translator_pair/sents_3/valid_ctrl_no_ctx_all_small.tsv -> 1500\n",
            "[gather_dipper_pos_val] Total valid-like files found: 176\n",
            "[load_dipper_val] Loaded DIPPER val: 8000 samples (label dist: {1: 5327, 0: 2673})\n",
            "Loading HC3 (Hello-SimpleAI/HC3, config='all') ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3935821506.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n",
            "/tmp/ipython-input-3935821506.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if pd.isna(x): return []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  HC3 train: no_ctx=60205 ctx=60205\n",
            "Built HC3-eval: 8000 samples\n",
            "Loaded custom CSV: 90 (pos/neg: {1: 60, 0: 30})\n",
            "\n",
            "Evaluating DIPPER_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3935821506.py:276: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/pd_mpnet/dipper_val_confusion_matrix.png\n",
            "Saved /content/output/pd_mpnet/dipper_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.38      1.00      0.55      2673\n",
            "    Paraphrase       0.99      0.17      0.29      5327\n",
            "\n",
            "      accuracy                           0.45      8000\n",
            "     macro avg       0.68      0.58      0.42      8000\n",
            "  weighted avg       0.79      0.45      0.38      8000\n",
            "\n",
            "\n",
            "Evaluating HC3_VAL (8000 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3935821506.py:276: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/pd_mpnet/hc3_val_confusion_matrix.png\n",
            "Saved /content/output/pd_mpnet/hc3_val_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.33      1.00      0.50      2664\n",
            "    Paraphrase       1.00      0.00      0.00      5336\n",
            "\n",
            "      accuracy                           0.33      8000\n",
            "     macro avg       0.67      0.50      0.25      8000\n",
            "  weighted avg       0.78      0.33      0.17      8000\n",
            "\n",
            "Saved summary.json to /content/output/pd_mpnet\n",
            "\n",
            "Evaluating CUSTOM_CSV (90 samples)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3935821506.py:276: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=USE_MIXED_PRECISION and torch.cuda.is_available(), dtype=amp_dtype):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved /content/output/pd_mpnet/custom_csv_confusion_matrix.png\n",
            "Saved /content/output/pd_mpnet/custom_csv_confusion_matrix_normalized.png\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "Not Paraphrase       0.85      0.93      0.89        30\n",
            "    Paraphrase       0.96      0.92      0.94        60\n",
            "\n",
            "      accuracy                           0.92        90\n",
            "     macro avg       0.91      0.93      0.91        90\n",
            "  weighted avg       0.93      0.92      0.92        90\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                            sentence1  \\\n",
              "0   The possibility of approximating a continuous ...   \n",
              "1   State-of-the-art object detection networks dep...   \n",
              "2   I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "3   Our evolutionary history suggests that there w...   \n",
              "4   The possibility of approximating a continuous ...   \n",
              "..                                                ...   \n",
              "85  The possibility of approximating a continuous ...   \n",
              "86  In fact, science and technology are clearly di...   \n",
              "87  I swear I wasn’t going to do a “Top Whatevers ...   \n",
              "88  Our evolutionary history suggests that there w...   \n",
              "89  We study a novel machine learning (ML) problem...   \n",
              "\n",
              "                                            sentence2  label  pred  \\\n",
              "0   Several studies have examined the ability of a...      1     1   \n",
              "1   Leading object detection networks rely on regi...      1     1   \n",
              "2   I had resolved not to write a \"Top Whatever\" b...      1     1   \n",
              "3   Indeed, science and technology are distinctly ...      0     0   \n",
              "4   Numerous research papers have investigated the...      1     1   \n",
              "..                                                ...    ...   ...   \n",
              "85  A feedforward neural network with one hidden l...      1     1   \n",
              "86  In a recent opinion piece in The Conversation,...      0     0   \n",
              "87  We investigate a new machine learning problem ...      0     0   \n",
              "88  Our evolutionary history indicates that there ...      1     1   \n",
              "89  We investigate a new machine learning problem ...      1     1   \n",
              "\n",
              "    prob_paraphrase  \n",
              "0          0.875344  \n",
              "1          0.995918  \n",
              "2          0.984598  \n",
              "3          0.000394  \n",
              "4          0.998125  \n",
              "..              ...  \n",
              "85         0.997959  \n",
              "86         0.000352  \n",
              "87         0.000281  \n",
              "88         0.998010  \n",
              "89         0.998919  \n",
              "\n",
              "[90 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3eb1bf8-9e9b-4360-adf6-527e3f8fcba2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>label</th>\n",
              "      <th>pred</th>\n",
              "      <th>prob_paraphrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Several studies have examined the ability of a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.875344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>State-of-the-art object detection networks dep...</td>\n",
              "      <td>Leading object detection networks rely on regi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.995918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>I had resolved not to write a \"Top Whatever\" b...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.984598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Indeed, science and technology are distinctly ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>Numerous research papers have investigated the...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>The possibility of approximating a continuous ...</td>\n",
              "      <td>A feedforward neural network with one hidden l...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.997959</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>In fact, science and technology are clearly di...</td>\n",
              "      <td>In a recent opinion piece in The Conversation,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>I swear I wasn’t going to do a “Top Whatevers ...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>Our evolutionary history suggests that there w...</td>\n",
              "      <td>Our evolutionary history indicates that there ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>We study a novel machine learning (ML) problem...</td>\n",
              "      <td>We investigate a new machine learning problem ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.998919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>90 rows × 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3eb1bf8-9e9b-4360-adf6-527e3f8fcba2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e3eb1bf8-9e9b-4360-adf6-527e3f8fcba2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e3eb1bf8-9e9b-4360-adf6-527e3f8fcba2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6bab72ea-ecaa-4a94-ad11-8aa6793b9e0e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6bab72ea-ecaa-4a94-ad11-8aa6793b9e0e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6bab72ea-ecaa-4a94-ad11-8aa6793b9e0e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    print(\\\"No custom CSV results to display\",\n  \"rows\": 90,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Andrew Ng hands me a tiny device that wraps around my ear and connects to a smartphone via a small cable. It looks like a throwback---a smartphone earpiece without a Bluetooth connection. But it's really a glimpse of the future. In a way, this tiny device allows the blind to see.\",\n          \"The possibility of approximating a continuous function on a compact subset of the real line by a feedforward single hidden layer neural network with a sigmoidal activation function has been studied in many papers. \",\n          \"We study a novel machine learning (ML) problem setting of sequentially allocating small subsets of training data amongst a large set of classifiers. The goal is to select a classifier that will give near-optimal accuracy when trained on all data, while also minimizing the cost of misallocated samples.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Several studies have examined the ability of a single hidden layer feedforward neural network with a sigmoidal activation function to approximate a continuous function on a compact subset of the real line.\",\n          \"Professor Lord Krebs stated in a recent opinion article in The Conversation that \\\"accurate reporting of science matters\\\" and that scientists have a professional obligation to \\\"challenge poor media reporting on climate change\\\".\",\n          \"I promise I had no intention of writing a \\\"Top Whatevers of 2015\\\" blog post this year, but then Slate's Benevolent Overlords requested I write one, and what option did I have? They're benevolent, yet they remain overlords. Additionally, I'm fond of them.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pred\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prob_paraphrase\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4785754991476943,\n        \"min\": 0.0002782531955745071,\n        \"max\": 0.999344527721405,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.9883041381835938,\n          0.8753436207771301\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved custom_results.csv to /content/output/pd_mpnet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "UoOVVyWVccZU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/output.zip /content/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydRScgVf5sVf",
        "outputId": "8dc63ba8-e9f6-4bb9-90a0-ed1be60b301c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/deberta_v3_mrpc/ (stored 0%)\n",
            "  adding: content/output/deberta_v3_mrpc/hc3_val_metrics.json (deflated 39%)\n",
            "  adding: content/output/deberta_v3_mrpc/custom_csv_confusion_matrix.png (deflated 18%)\n",
            "  adding: content/output/deberta_v3_mrpc/custom_csv_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/deberta_v3_mrpc/custom_results.csv (deflated 87%)\n",
            "  adding: content/output/deberta_v3_mrpc/summary.json (deflated 59%)\n",
            "  adding: content/output/deberta_v3_mrpc/dipper_val_metrics.json (deflated 37%)\n",
            "  adding: content/output/deberta_v3_mrpc/dipper_val_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/deberta_v3_mrpc/hc3_val_confusion_matrix_normalized.png (deflated 17%)\n",
            "  adding: content/output/deberta_v3_mrpc/dipper_val_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/deberta_v3_mrpc/hc3_val_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/deberta_v3_mrpc/custom_csv_metrics.json (deflated 43%)\n",
            "  adding: content/output/roberta_mrpc/ (stored 0%)\n",
            "  adding: content/output/roberta_mrpc/hc3_val_metrics.json (deflated 37%)\n",
            "  adding: content/output/roberta_mrpc/custom_csv_confusion_matrix.png (deflated 18%)\n",
            "  adding: content/output/roberta_mrpc/custom_csv_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/roberta_mrpc/custom_results.csv (deflated 86%)\n",
            "  adding: content/output/roberta_mrpc/summary.json (deflated 59%)\n",
            "  adding: content/output/roberta_mrpc/dipper_val_metrics.json (deflated 37%)\n",
            "  adding: content/output/roberta_mrpc/dipper_val_confusion_matrix.png (deflated 16%)\n",
            "  adding: content/output/roberta_mrpc/hc3_val_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/roberta_mrpc/dipper_val_confusion_matrix_normalized.png (deflated 17%)\n",
            "  adding: content/output/roberta_mrpc/hc3_val_confusion_matrix.png (deflated 18%)\n",
            "  adding: content/output/roberta_mrpc/custom_csv_metrics.json (deflated 45%)\n",
            "  adding: content/output/bert_mrpc/ (stored 0%)\n",
            "  adding: content/output/bert_mrpc/hc3_val_metrics.json (deflated 37%)\n",
            "  adding: content/output/bert_mrpc/custom_csv_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/bert_mrpc/custom_csv_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/bert_mrpc/custom_results.csv (deflated 86%)\n",
            "  adding: content/output/bert_mrpc/summary.json (deflated 58%)\n",
            "  adding: content/output/bert_mrpc/dipper_val_metrics.json (deflated 36%)\n",
            "  adding: content/output/bert_mrpc/dipper_val_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/bert_mrpc/hc3_val_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/bert_mrpc/dipper_val_confusion_matrix_normalized.png (deflated 17%)\n",
            "  adding: content/output/bert_mrpc/hc3_val_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/bert_mrpc/custom_csv_metrics.json (deflated 43%)\n",
            "  adding: content/output/pd_mpnet/ (stored 0%)\n",
            "  adding: content/output/pd_mpnet/hc3_val_metrics.json (deflated 38%)\n",
            "  adding: content/output/pd_mpnet/custom_csv_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/pd_mpnet/custom_csv_confusion_matrix_normalized.png (deflated 15%)\n",
            "  adding: content/output/pd_mpnet/custom_results.csv (deflated 86%)\n",
            "  adding: content/output/pd_mpnet/summary.json (deflated 58%)\n",
            "  adding: content/output/pd_mpnet/dipper_val_metrics.json (deflated 37%)\n",
            "  adding: content/output/pd_mpnet/dipper_val_confusion_matrix.png (deflated 17%)\n",
            "  adding: content/output/pd_mpnet/hc3_val_confusion_matrix_normalized.png (deflated 16%)\n",
            "  adding: content/output/pd_mpnet/dipper_val_confusion_matrix_normalized.png (deflated 17%)\n",
            "  adding: content/output/pd_mpnet/hc3_val_confusion_matrix.png (deflated 18%)\n",
            "  adding: content/output/pd_mpnet/custom_csv_metrics.json (deflated 43%)\n"
          ]
        }
      ]
    }
  ]
}